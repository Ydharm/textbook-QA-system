{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21bd6a24-2fd6-4bde-9909-1c0f9d451f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e3fee4-dfda-418e-87ad-e401461352d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text from page 0: ...\n",
      "Extracted text from page 1: ...\n",
      "Extracted text from page 2: Data\tScience\tfrom\tScratch\n",
      "\n",
      "Joel\tGrus\n",
      "\n",
      "...\n",
      "Extracted text from page 3: ...\n",
      "Extracted text from page 4: Data\tScience\tfrom\tScratch\n",
      "\n",
      "by\tJoel\tGrus\n",
      "\n",
      "Copyright\t©\t2015\tO’Reilly\tMedia.\tAll\trights\treserved.\n",
      "\n",
      "Prin...\n",
      "Extracted text from page 5: Revision\tHistory\tfor\tthe\tFirst\tEdition\n",
      "\n",
      "2015-04-10:\tFirst\tRelease\n",
      "\n",
      "See\thttp://oreilly.com/catalog/er...\n",
      "Extracted text from page 6: ...\n",
      "Extracted text from page 7: Preface\n",
      "\n",
      "...\n",
      "Extracted text from page 8: Data\tScience\n",
      "\n",
      "Data\tscientist\thas\tbeen\tcalled\t“the\tsexiest\tjob\tof\tthe\t21st\tcentury,”\tpresumably\tby\n",
      "so...\n",
      "Extracted text from page 9: From\tScratch\n",
      "\n",
      "There\tare\tlots\tand\tlots\tof\tdata\tscience\tlibraries,\tframeworks,\tmodules,\tand\ttoolkits\tt...\n",
      "Extracted text from page 10: Over\tthe\tyears,\tI’ve\ttrained\ta\tnumber\tof\tdata\tscientists.\tWhile\tnot\tall\tof\tthem\thave\tgone\n",
      "on\tto\tbeco...\n",
      "Extracted text from page 11: Conventions\tUsed\tin\tThis\tBook\n",
      "\n",
      "The\tfollowing\ttypographical\tconventions\tare\tused\tin\tthis\tbook:\n",
      "\n",
      "Itali...\n",
      "Extracted text from page 12: Using\tCode\tExamples\n",
      "\n",
      "Supplemental\tmaterial\t(code\texamples,\texercises,\tetc.)\tis\tavailable\tfor\tdownloa...\n",
      "Extracted text from page 13: Safari®\tBooks\tOnline\n",
      "\n",
      "NOTE\n",
      "\n",
      "Safari\tBooks\tOnline\tis\tan\ton-demand\tdigital\tlibrary\tthat\tdelivers\texpert...\n",
      "Extracted text from page 14: How\tto\tContact\tUs\n",
      "\n",
      "Please\taddress\tcomments\tand\tquestions\tconcerning\tthis\tbook\tto\tthe\tpublisher:\n",
      "\n",
      "O’R...\n",
      "Extracted text from page 15: Acknowledgments\n",
      "\n",
      "First,\tI\twould\tlike\tto\tthank\tMike\tLoukides\tfor\taccepting\tmy\tproposal\tfor\tthis\tbook\t...\n",
      "Extracted text from page 16: ...\n",
      "Extracted text from page 17: Chapter\t1.\tIntroduction\n",
      "\n",
      "“Data!\tData!\tData!”\the\tcried\timpatiently.\t“I\tcan’t\tmake\tbricks\twithout\tclay...\n",
      "Extracted text from page 18: The\tAscendance\tof\tData\n",
      "\n",
      "We\tlive\tin\ta\tworld\tthat’s\tdrowning\tin\tdata.\tWebsites\ttrack\tevery\tuser’s\tever...\n",
      "Extracted text from page 19: What\tIs\tData\tScience?\n",
      "\n",
      "There’s\ta\tjoke\tthat\tsays\ta\tdata\tscientist\tis\tsomeone\twho\tknows\tmore\tstatistic...\n",
      "Extracted text from page 20: Motivating\tHypothetical:\tDataSciencester\n",
      "\n",
      "Congratulations!\tYou’ve\tjust\tbeen\thired\tto\tlead\tthe\tdata\ts...\n",
      "Extracted text from page 21: Finding\tKey\tConnectors\n",
      "\n",
      "It’s\tyour\tfirst\tday\ton\tthe\tjob\tat\tDataSciencester,\tand\tthe\tVP\tof\tNetworking\t...\n",
      "Extracted text from page 22: For\texample,\twe\tmight\twant\tto\tadd\ta\tlist\tof\tfriends\tto\teach\tuser.\tFirst\twe\tset\teach\tuser’s\n",
      "friends\tp...\n",
      "Extracted text from page 23: Figure\t1-2.\tThe\tDataSciencester\tnetwork\tsized\tby\tdegree\n",
      "\n",
      "This\thas\tthe\tvirtue\tof\tbeing\tpretty\teasy\tto...\n",
      "Extracted text from page 24: Data\tScientists\tYou\tMay\tKnow\n",
      "\n",
      "While\tyou’re\tstill\tfilling\tout\tnew-hire\tpaperwork,\tthe\tVP\tof\tFraterniz...\n",
      "Extracted text from page 25: interests.\t(This\tis\ta\tgood\texample\tof\tthe\t“substantive\texpertise”\taspect\tof\tdata\tscience.)\n",
      "After\task...\n",
      "Extracted text from page 26: def\tmost_common_interests_with(user):\n",
      "\t\t\t\treturn\tCounter(interested_user_id\n",
      "\t\t\t\t\t\t\t\tfor\tinterest\tin\t...\n",
      "Extracted text from page 27: Salaries\tand\tExperience\n",
      "\n",
      "Right\tas\tyou’re\tabout\tto\thead\tto\tlunch,\tthe\tVP\tof\tPublic\tRelations\tasks\tif\t...\n",
      "Extracted text from page 28: #\tkeys\tare\tyears,\teach\tvalue\tis\taverage\tsalary\tfor\tthat\ttenure\n",
      "average_salary_by_tenure\t=\t{\n",
      "\t\t\t\ttenu...\n",
      "Extracted text from page 29: experience.\tIn\taddition\tto\tmaking\tfor\ta\tsnappier\tfun\tfact,\tthis\tallows\tus\tto\tmake\n",
      "predictions\tabout\t...\n",
      "Extracted text from page 30: Paid\tAccounts\n",
      "\n",
      "When\tyou\tget\tback\tto\tyour\tdesk,\tthe\tVP\tof\tRevenue\tis\twaiting\tfor\tyou.\tShe\twants\tto\n",
      "be...\n",
      "Extracted text from page 31: Topics\tof\tInterest\n",
      "\n",
      "As\tyou’re\twrapping\tup\tyour\tfirst\tday,\tthe\tVP\tof\tContent\tStrategy\tasks\tyou\tfor\tda...\n",
      "Extracted text from page 32: networks\t2\n",
      "machine\t2\n",
      "neural\t2\n",
      "scikit-learn\t2\n",
      "r\t2\n",
      "\n",
      "We’ll\tlook\tat\tmore\tsophisticated\tways\tto\textract\tt...\n",
      "Extracted text from page 33: Onward\n",
      "\n",
      "It’s\tbeen\ta\tsuccessful\tfirst\tday!\tExhausted,\tyou\tslip\tout\tof\tthe\tbuilding\tbefore\tanyone\telse...\n",
      "Extracted text from page 34: ...\n",
      "Extracted text from page 35: Chapter\t2.\tA\tCrash\tCourse\tin\tPython\n",
      "\n",
      "People\tare\tstill\tcrazy\tabout\tPython\tafter\ttwenty-five\tyears,\twh...\n",
      "Extracted text from page 36: The\tBasics\n",
      "\n",
      "...\n",
      "Extracted text from page 37: Getting\tPython\n",
      "\n",
      "You\tcan\tdownload\tPython\tfrom\tpython.org.\tBut\tif\tyou\tdon’t\talready\thave\tPython,\tI\n",
      "rec...\n",
      "Extracted text from page 38: The\tZen\tof\tPython\n",
      "\n",
      "Python\thas\ta\tsomewhat\tZen\tdescription\tof\tits\tdesign\tprinciples,\twhich\tyou\tcan\tals...\n",
      "Extracted text from page 39: Whitespace\tFormatting\n",
      "\n",
      "Many\tlanguages\tuse\tcurly\tbraces\tto\tdelimit\tblocks\tof\tcode.\tPython\tuses\tindent...\n",
      "Extracted text from page 40: Modules\n",
      "\n",
      "Certain\tfeatures\tof\tPython\tare\tnot\tloaded\tby\tdefault.\tThese\tinclude\tboth\tfeatures\tincluded\n",
      "...\n",
      "Extracted text from page 41: Arithmetic\n",
      "\n",
      "Python\t2.7\tuses\tinteger\tdivision\tby\tdefault,\tso\tthat\t5\t/\t2\tequals\t2.\tAlmost\talways\tthis\t...\n",
      "Extracted text from page 42: Functions\n",
      "\n",
      "A\tfunction\tis\ta\trule\tfor\ttaking\tzero\tor\tmore\tinputs\tand\treturning\ta\tcorresponding\toutput....\n",
      "Extracted text from page 43: Strings\n",
      "\n",
      "Strings\tcan\tbe\tdelimited\tby\tsingle\tor\tdouble\tquotation\tmarks\t(but\tthe\tquotes\thave\tto\n",
      "match)...\n",
      "Extracted text from page 44: Exceptions\n",
      "\n",
      "When\tsomething\tgoes\twrong,\tPython\traises\tan\texception.\tUnhandled,\tthese\twill\tcause\n",
      "your\t...\n",
      "Extracted text from page 45: Lists\n",
      "\n",
      "Probably\tthe\tmost\tfundamental\tdata\tstructure\tin\tPython\tis\tthe\tlist.\tA\tlist\tis\tsimply\tan\n",
      "order...\n",
      "Extracted text from page 46: It\tis\toften\tconvenient\tto\tunpack\tlists\tif\tyou\tknow\thow\tmany\telements\tthey\tcontain:\n",
      "\n",
      "x,\ty\t=\t[1,\t2]\t\t\t...\n",
      "Extracted text from page 47: Tuples\n",
      "\n",
      "Tuples\tare\tlists’\timmutable\tcousins.\tPretty\tmuch\tanything\tyou\tcan\tdo\tto\ta\tlist\tthat\tdoesn’t\n",
      "...\n",
      "Extracted text from page 48: Dictionaries\n",
      "\n",
      "Another\tfundamental\tdata\tstructure\tis\ta\tdictionary,\twhich\tassociates\tvalues\twith\tkeys\t...\n",
      "Extracted text from page 49: \"joelgrus\"\tin\ttweet_values\t\t\t\t\t\t#\tTrue\n",
      "\n",
      "Dictionary\tkeys\tmust\tbe\timmutable;\tin\tparticular,\tyou\tcannot...\n",
      "Extracted text from page 50: dd_dict\t=\tdefaultdict(dict)\t\t\t\t\t\t\t\t\t\t\t\t\t#\tdict()\tproduces\tan\tempty\tdict\n",
      "dd_dict[\"Joel\"][\"City\"]\t=\t\"S...\n",
      "Extracted text from page 51: Sets\n",
      "\n",
      "Another\tdata\tstructure\tis\tset,\twhich\trepresents\ta\tcollection\tof\tdistinct\telements:\n",
      "\n",
      "s\t=\tset()\n",
      "...\n",
      "Extracted text from page 52: Control\tFlow\n",
      "\n",
      "As\tin\tmost\tprogramming\tlanguages,\tyou\tcan\tperform\tan\taction\tconditionally\tusing\tif:\n",
      "\n",
      "i...\n",
      "Extracted text from page 53: Truthiness\n",
      "\n",
      "Booleans\tin\tPython\twork\tas\tin\tmost\tother\tlanguages,\texcept\tthat\tthey’re\tcapitalized:\n",
      "\n",
      "on...\n",
      "Extracted text from page 54: is\tdefinitely\ta\tnumber.\n",
      "\n",
      "Python\thas\tan\tall\tfunction,\twhich\ttakes\ta\tlist\tand\treturns\tTrue\tprecisely\tw...\n",
      "Extracted text from page 55: The\tNot-So-Basics\n",
      "\n",
      "Here\twe’ll\tlook\tat\tsome\tmore-advanced\tPython\tfeatures\tthat\twe’ll\tfind\tuseful\tfor\t...\n",
      "Extracted text from page 56: Sorting\n",
      "\n",
      "Every\tPython\tlist\thas\ta\tsort\tmethod\tthat\tsorts\tit\tin\tplace.\tIf\tyou\tdon’t\twant\tto\tmess\tup\n",
      "yo...\n",
      "Extracted text from page 57: List\tComprehensions\n",
      "\n",
      "Frequently,\tyou’ll\twant\tto\ttransform\ta\tlist\tinto\tanother\tlist,\tby\tchoosing\tonly...\n",
      "Extracted text from page 58: Generators\tand\tIterators\n",
      "\n",
      "A\tproblem\twith\tlists\tis\tthat\tthey\tcan\teasily\tgrow\tvery\tbig.\trange(1000000)...\n",
      "Extracted text from page 59: Randomness\n",
      "\n",
      "As\twe\tlearn\tdata\tscience,\twe\twill\tfrequently\tneed\tto\tgenerate\trandom\tnumbers,\twhich\twe\n",
      "c...\n",
      "Extracted text from page 60: Regular\tExpressions\n",
      "\n",
      "Regular\texpressions\tprovide\ta\tway\tof\tsearching\ttext.\tThey\tare\tincredibly\tuseful...\n",
      "Extracted text from page 61: Object-Oriented\tProgramming\n",
      "\n",
      "Like\tmany\tlanguages,\tPython\tallows\tyou\tto\tdefine\tclasses\tthat\tencapsula...\n",
      "Extracted text from page 62: Functional\tTools\n",
      "\n",
      "When\tpassing\tfunctions\taround,\tsometimes\twe’ll\twant\tto\tpartially\tapply\t(or\tcurry)\n",
      "...\n",
      "Extracted text from page 63: x_evens\t=\t[x\tfor\tx\tin\txs\tif\tis_even(x)]\t\t\t\t#\t[2,\t4]\n",
      "x_evens\t=\tfilter(is_even,\txs)\t\t\t\t\t\t\t\t\t\t\t\t\t\t#\tsam...\n",
      "Extracted text from page 64: enumerate\n",
      "\n",
      "Not\tinfrequently,\tyou’ll\twant\tto\titerate\tover\ta\tlist\tand\tuse\tboth\tits\telements\tand\ttheir\n",
      "...\n",
      "Extracted text from page 65: zip\tand\tArgument\tUnpacking\n",
      "\n",
      "Often\twe\twill\tneed\tto\tzip\ttwo\tor\tmore\tlists\ttogether.\tzip\ttransforms\tmul...\n",
      "Extracted text from page 66: args\tand\tkwargs\n",
      "\n",
      "Let’s\tsay\twe\twant\tto\tcreate\ta\thigher-order\tfunction\tthat\ttakes\tas\tinput\tsome\tfuncti...\n",
      "Extracted text from page 67: \t\t\t\t\t\t\t\t\"\"\"whatever\targuments\tg\tis\tsupplied,\tpass\tthem\tthrough\tto\tf\"\"\"\n",
      "\t\t\t\t\t\t\t\treturn\t2\t*\tf(*args,\t*...\n",
      "Extracted text from page 68: Welcome\tto\tDataSciencester!\n",
      "\n",
      "This\tconcludes\tnew-employee\torientation.\tOh,\tand\talso,\ttry\tnot\tto\tembez...\n",
      "Extracted text from page 69: For\tFurther\tExploration\n",
      "\n",
      "There\tis\tno\tshortage\tof\tPython\ttutorials\tin\tthe\tworld.\tThe\tofficial\tone\tis\t...\n",
      "Extracted text from page 70: ...\n",
      "Extracted text from page 71: Chapter\t3.\tVisualizing\tData\n",
      "\n",
      "I\tbelieve\tthat\tvisualization\tis\tone\tof\tthe\tmost\tpowerful\tmeans\tof\tachie...\n",
      "Extracted text from page 72: matplotlib\n",
      "\n",
      "A\twide\tvariety\tof\ttools\texists\tfor\tvisualizing\tdata.\tWe\twill\tbe\tusing\tthe\tmatplotlib\n",
      "lib...\n",
      "Extracted text from page 73: Making\tplots\tthat\tlook\tpublication-quality\tgood\tis\tmore\tcomplicated\tand\tbeyond\tthe\n",
      "scope\tof\tthis\tcha...\n",
      "Extracted text from page 74: Bar\tCharts\n",
      "\n",
      "A\tbar\tchart\tis\ta\tgood\tchoice\twhen\tyou\twant\tto\tshow\thow\tsome\tquantity\tvaries\tamong\n",
      "some\td...\n",
      "Extracted text from page 75: grades\t=\t[83,95,91,87,70,0,85,82,100,67,73,77,0]\n",
      "decile\t=\tlambda\tgrade:\tgrade\t//\t10\t*\t10\n",
      "histogram\t=...\n",
      "Extracted text from page 76: Be\tjudicious\twhen\tusing\tplt.axis().\tWhen\tcreating\tbar\tcharts\tit\tis\tconsidered\tespecially\n",
      "bad\tform\tfo...\n",
      "Extracted text from page 77: Figure\t3-5.\tThe\tsame\tchart\twith\ta\tnonmisleading\ty-axis\n",
      "\n",
      "...\n",
      "Extracted text from page 78: Line\tCharts\n",
      "\n",
      "As\twe\tsaw\talready,\twe\tcan\tmake\tline\tcharts\tusing\tplt.plot().\tThese\tare\ta\tgood\tchoice\n",
      "fo...\n",
      "Extracted text from page 79: Scatterplots\n",
      "\n",
      "A\tscatterplot\tis\tthe\tright\tchoice\tfor\tvisualizing\tthe\trelationship\tbetween\ttwo\tpaired\t...\n",
      "Extracted text from page 80: test_1_grades\t=\t[\t99,\t90,\t85,\t97,\t80]\n",
      "test_2_grades\t=\t[100,\t85,\t60,\t90,\t70]\n",
      "\n",
      "plt.scatter(test_1_grad...\n",
      "Extracted text from page 81: Figure\t3-9.\tThe\tsame\tscatterplot\twith\tequal\taxes\n",
      "\n",
      "...\n",
      "Extracted text from page 82: For\tFurther\tExploration\n",
      "\n",
      "seaborn\tis\tbuilt\ton\ttop\tof\tmatplotlib\tand\tallows\tyou\tto\teasily\tproduce\tpret...\n",
      "Extracted text from page 83: ...\n",
      "Extracted text from page 84: Chapter\t4.\tLinear\tAlgebra\n",
      "\n",
      "Is\tthere\tanything\tmore\tuseless\tor\tless\tuseful\tthan\tAlgebra?\n",
      "\n",
      "Billy\tConnol...\n",
      "Extracted text from page 85: Vectors\n",
      "\n",
      "Abstractly,\tvectors\tare\tobjects\tthat\tcan\tbe\tadded\ttogether\t(to\tform\tnew\tvectors)\tand\tthat\n",
      "c...\n",
      "Extracted text from page 86: Figure\t4-1.\tAdding\ttwo\tvectors\n",
      "\n",
      "We\tcan\teasily\timplement\tthis\tby\tzip-ing\tthe\tvectors\ttogether\tand\tusi...\n",
      "Extracted text from page 87: If\tyou\tthink\tabout\tit,\twe\tare\tjust\treduce-ing\tthe\tlist\tof\tvectors\tusing\tvector_add,\twhich\n",
      "means\twe\tc...\n",
      "Extracted text from page 88: Figure\t4-2.\tThe\tdot\tproduct\tas\tvector\tprojection\n",
      "\n",
      "Using\tthis,\tit’s\teasy\tto\tcompute\ta\tvector’s\tsum\tof...\n",
      "Extracted text from page 89: \t\t\treturn\tmath.sqrt(squared_distance(v,\tw))\n",
      "\n",
      "Which\tis\tpossibly\tclearer\tif\twe\twrite\tit\tas\t(the\tequiva...\n",
      "Extracted text from page 90: Matrices\n",
      "\n",
      "A\tmatrix\tis\ta\ttwo-dimensional\tcollection\tof\tnumbers.\tWe\twill\trepresent\tmatrices\tas\tlists\n",
      "o...\n",
      "Extracted text from page 91: \t\t\t\t\"\"\"1's\ton\tthe\t'diagonal',\t0's\teverywhere\telse\"\"\"\n",
      "\t\t\t\treturn\t1\tif\ti\t==\tj\telse\t0\n",
      "\n",
      "identity_matrix\t...\n",
      "Extracted text from page 92: friendships[0][2]\t==\t1\t\t\t#\tTrue,\t0\tand\t2\tare\tfriends\n",
      "friendships[0][8]\t==\t1\t\t\t#\tFalse,\t0\tand\t8\tare\tn...\n",
      "Extracted text from page 93: For\tFurther\tExploration\n",
      "\n",
      "Linear\talgebra\tis\twidely\tused\tby\tdata\tscientists\t(frequently\timplicitly,\tan...\n",
      "Extracted text from page 94: ...\n",
      "Extracted text from page 95: Chapter\t5.\tStatistics\n",
      "\n",
      "Facts\tare\tstubborn,\tbut\tstatistics\tare\tmore\tpliable.\n",
      "\n",
      "Mark\tTwain\n",
      "\n",
      "Statistics\t...\n",
      "Extracted text from page 96: Describing\ta\tSingle\tSet\tof\tData\n",
      "\n",
      "Through\ta\tcombination\tof\tword-of-mouth\tand\tluck,\tDataSciencester\tha...\n",
      "Extracted text from page 97: Figure\t5-1.\tA\thistogram\tof\tfriend\tcounts\n",
      "\n",
      "Unfortunately,\tthis\tchart\tis\tstill\ttoo\tdifficult\tto\tslip\ti...\n",
      "Extracted text from page 98: Central\tTendencies\n",
      "\n",
      "Usually,\twe’ll\twant\tsome\tnotion\tof\twhere\tour\tdata\tis\tcentered.\tMost\tcommonly\twe’...\n",
      "Extracted text from page 99: NOTE\n",
      "\n",
      "There\tare,\tin\tfact,\tnonobvious\ttricks\tto\tefficiently\tcompute\tmedians\twithout\tsorting\tthe\tdata....\n",
      "Extracted text from page 100: Dispersion\n",
      "\n",
      "Dispersion\trefers\tto\tmeasures\tof\thow\tspread\tout\tour\tdata\tis.\tTypically\tthey’re\tstatistic...\n",
      "Extracted text from page 101: earlier\tfor\tthe\tmean.\tUsing\tthe\tsame\texample,\tif\tour\tfriendliest\tuser\thad\tinstead\t200\n",
      "friends,\tthe\ts...\n",
      "Extracted text from page 102: Correlation\n",
      "\n",
      "DataSciencester’s\tVP\tof\tGrowth\thas\ta\ttheory\tthat\tthe\tamount\tof\ttime\tpeople\tspend\ton\tthe...\n",
      "Extracted text from page 103: The\tcorrelation\tis\tunitless\tand\talways\tlies\tbetween\t-1\t(perfect\tanti-correlation)\tand\t1\n",
      "(perfect\tcor...\n",
      "Extracted text from page 104: Figure\t5-3.\tCorrelation\tafter\tremoving\tthe\toutlier\n",
      "\n",
      "You\tinvestigate\tfurther\tand\tdiscover\tthat\tthe\tou...\n",
      "Extracted text from page 105: Simpson’s\tParadox\n",
      "\n",
      "One\tnot\tuncommon\tsurprise\twhen\tanalyzing\tdata\tis\tSimpson’s\tParadox,\tin\twhich\n",
      "corr...\n",
      "Extracted text from page 106: might\tsimply\tconclude\tthat\tthere\twas\tsomething\tinherently\tmore\tsociable\tabout\tthe\tWest\n",
      "Coast.\n",
      "\n",
      "...\n",
      "Extracted text from page 107: Some\tOther\tCorrelational\tCaveats\n",
      "\n",
      "A\tcorrelation\tof\tzero\tindicates\tthat\tthere\tis\tno\tlinear\trelationsh...\n",
      "Extracted text from page 108: Correlation\tand\tCausation\n",
      "\n",
      "You\thave\tprobably\theard\tat\tsome\tpoint\tthat\t“correlation\tis\tnot\tcausation,...\n",
      "Extracted text from page 109: For\tFurther\tExploration\n",
      "\n",
      "SciPy,\tpandas,\tand\tStatsModels\tall\tcome\twith\ta\twide\tvariety\tof\tstatistical\t...\n",
      "Extracted text from page 110: ...\n",
      "Extracted text from page 111: Chapter\t6.\tProbability\n",
      "\n",
      "The\tlaws\tof\tprobability,\tso\ttrue\tin\tgeneral,\tso\tfallacious\tin\tparticular.\n",
      "\n",
      "E...\n",
      "Extracted text from page 112: Dependence\tand\tIndependence\n",
      "\n",
      "Roughly\tspeaking,\twe\tsay\tthat\ttwo\tevents\tE\tand\tF\tare\tdependent\tif\tknowi...\n",
      "Extracted text from page 113: Conditional\tProbability\n",
      "\n",
      "When\ttwo\tevents\tE\tand\tF\tare\tindependent,\tthen\tby\tdefinition\twe\thave:\n",
      "\n",
      "If\tth...\n",
      "Extracted text from page 114: We\tcould\talso\task\tabout\tthe\tprobability\tof\tthe\tevent\t“both\tchildren\tare\tgirls”\tconditional\n",
      "on\tthe\tev...\n",
      "Extracted text from page 115: Bayes’s\tTheorem\n",
      "\n",
      "One\tof\tthe\tdata\tscientist’s\tbest\tfriends\tis\tBayes’s\tTheorem,\twhich\tis\ta\tway\tof\t“rev...\n",
      "Extracted text from page 116: While\tthis\tis\ta\tsimple\tcalculation\tfor\ta\tdata\tscientist,\tmost\tdoctors\twill\tguess\tthat\t\n",
      "\n",
      "\tis\tapproxim...\n",
      "Extracted text from page 117: Random\tVariables\n",
      "\n",
      "A\trandom\tvariable\tis\ta\tvariable\twhose\tpossible\tvalues\thave\tan\tassociated\tprobabili...\n",
      "Extracted text from page 118: Continuous\tDistributions\n",
      "\n",
      "A\tcoin\tflip\tcorresponds\tto\ta\tdiscrete\tdistribution\t—\tone\tthat\tassociates\tp...\n",
      "Extracted text from page 119: Figure\t6-1.\tThe\tuniform\tcdf\n",
      "\n",
      "...\n",
      "Extracted text from page 120: The\tNormal\tDistribution\n",
      "\n",
      "The\tnormal\tdistribution\tis\tthe\tking\tof\tdistributions.\tIt\tis\tthe\tclassic\tbel...\n",
      "Extracted text from page 121: Figure\t6-2.\tVarious\tnormal\tpdfs\n",
      "\n",
      "When\t\n",
      "normal\trandom\tvariable,\tthen\tit\tturns\tout\tthat:\n",
      "\n",
      "\tand\t\n",
      "\n",
      ",\tit’...\n",
      "Extracted text from page 122: plt.plot(xs,[normal_cdf(x,sigma=1)\tfor\tx\tin\txs],'-',label='mu=0,sigma=1')\n",
      "plt.plot(xs,[normal_cdf(x,...\n",
      "Extracted text from page 123: \t\t\t\t\t\t\t\t\t\t\t\tbreak\n",
      "\n",
      "\t\t\t\treturn\tmid_z\n",
      "\n",
      "The\tfunction\trepeatedly\tbisects\tintervals\tuntil\tit\tnarrows\tin\to...\n",
      "Extracted text from page 124: The\tCentral\tLimit\tTheorem\n",
      "\n",
      "One\treason\tthe\tnormal\tdistribution\tis\tso\tuseful\tis\tthe\tcentral\tlimit\ttheo...\n",
      "Extracted text from page 125: \t\t\t\t#\tuse\ta\tline\tchart\tto\tshow\tthe\tnormal\tapproximation\n",
      "\t\t\t\txs\t=\trange(min(data),\tmax(data)\t+\t1)\n",
      "\t\t\t...\n",
      "Extracted text from page 126: For\tFurther\tExploration\n",
      "\n",
      "scipy.stats\tcontains\tpdf\tand\tcdf\tfunctions\tfor\tmost\tof\tthe\tpopular\tprobabil...\n",
      "Extracted text from page 127: ...\n",
      "Extracted text from page 128: Chapter\t7.\tHypothesis\tand\tInference\n",
      "\n",
      "It\tis\tthe\tmark\tof\ta\ttruly\tintelligent\tperson\tto\tbe\tmoved\tby\tsta...\n",
      "Extracted text from page 129: Statistical\tHypothesis\tTesting\n",
      "\n",
      "Often,\tas\tdata\tscientists,\twe’ll\twant\tto\ttest\twhether\ta\tcertain\thypo...\n",
      "Extracted text from page 130: Example:\tFlipping\ta\tCoin\n",
      "\n",
      "Imagine\twe\thave\ta\tcoin\tand\twe\twant\tto\ttest\twhether\tit’s\tfair.\tWe’ll\tmake\tt...\n",
      "Extracted text from page 131: \t\t\t\t#\tlower\tbound\tshould\thave\ttail_probability\tbelow\tit\n",
      "\t\t\t\tlower_bound\t=\tnormal_upper_bound(tail_pr...\n",
      "Extracted text from page 132: power\t=\t1\t-\ttype_2_probability\t\t\t\t\t\t#\t0.936\n",
      "\n",
      "This\tis\ta\tmore\tpowerful\ttest,\tsince\tit\tno\tlonger\treject...\n",
      "Extracted text from page 133: Similarly,\twe\twould\thave:\n",
      "\n",
      "upper_p_value\t=\tnormal_probability_above\n",
      "lower_p_value\t=\tnormal_probabili...\n",
      "Extracted text from page 134: Confidence\tIntervals\n",
      "\n",
      "We’ve\tbeen\ttesting\thypotheses\tabout\tthe\tvalue\tof\tthe\theads\tprobability\tp,\twhic...\n",
      "Extracted text from page 135: P-hacking\n",
      "\n",
      "A\tprocedure\tthat\terroneously\trejects\tthe\tnull\thypothesis\tonly\t5%\tof\tthe\ttime\twill\t—\tby\n",
      "de...\n",
      "Extracted text from page 136: Example:\tRunning\tan\tA/B\tTest\n",
      "\n",
      "One\tof\tyour\tprimary\tresponsibilities\tat\tDataSciencester\tis\texperience\t...\n",
      "Extracted text from page 137: z\t=\ta_b_test_statistic(1000,\t200,\t1000,\t180)\t\t\t\t#\t-1.14\n",
      "\n",
      "The\tprobability\tof\tseeing\tsuch\ta\tlarge\tdiff...\n",
      "Extracted text from page 138: Bayesian\tInference\n",
      "\n",
      "The\tprocedures\twe’ve\tlooked\tat\thave\tinvolved\tmaking\tprobability\tstatements\tabout...\n",
      "Extracted text from page 139: NOTE\n",
      "\n",
      "It\tis\tno\tcoincidence\tthat\tthe\tposterior\tdistribution\twas\tagain\ta\tBeta\tdistribution.\tThe\tnumber...\n",
      "Extracted text from page 140: Figure\t7-2.\tPosteriors\tarising\tfrom\tdifferent\tpriors\n",
      "\n",
      "If\tyou\tflipped\tthe\tcoin\tmore\tand\tmore\ttimes,\tt...\n",
      "Extracted text from page 141: For\tFurther\tExploration\n",
      "\n",
      "We’ve\tbarely\tscratched\tthe\tsurface\tof\twhat\tyou\tshould\tknow\tabout\tstatistica...\n",
      "Extracted text from page 142: ...\n",
      "Extracted text from page 143: Chapter\t8.\tGradient\tDescent\n",
      "\n",
      "Those\twho\tboast\tof\ttheir\tdescent,\tbrag\ton\twhat\tthey\towe\tto\tothers.\n",
      "\n",
      "Sen...\n",
      "Extracted text from page 144: The\tIdea\tBehind\tGradient\tDescent\n",
      "\n",
      "Suppose\twe\thave\tsome\tfunction\tf\tthat\ttakes\tas\tinput\ta\tvector\tof\tre...\n",
      "Extracted text from page 145: Estimating\tthe\tGradient\n",
      "\n",
      "If\tf\tis\ta\tfunction\tof\tone\tvariable,\tits\tderivative\tat\ta\tpoint\tx\tmeasures\tho...\n",
      "Extracted text from page 146: def\tsquare(x):\n",
      "\t\t\t\treturn\tx\t*\tx\n",
      "\n",
      "has\tthe\tderivative:\n",
      "\n",
      "def\tderivative(x):\n",
      "\t\t\t\treturn\t2\t*\tx\n",
      "\n",
      "which\tyou...\n",
      "Extracted text from page 147: When\tf\tis\ta\tfunction\tof\tmany\tvariables,\tit\thas\tmultiple\tpartial\tderivatives,\teach\tindicating\n",
      "how\tf\tc...\n",
      "Extracted text from page 148: Using\tthe\tGradient\n",
      "\n",
      "It’s\teasy\tto\tsee\tthat\tthe\tsum_of_squares\tfunction\tis\tsmallest\twhen\tits\tinput\tv\ti...\n",
      "Extracted text from page 149: Choosing\tthe\tRight\tStep\tSize\n",
      "\n",
      "Although\tthe\trationale\tfor\tmoving\tagainst\tthe\tgradient\tis\tclear,\thow\tf...\n",
      "Extracted text from page 150: Putting\tIt\tAll\tTogether\n",
      "\n",
      "In\tthe\tgeneral\tcase,\twe\thave\tsome\ttarget_fn\tthat\twe\twant\tto\tminimize,\tand\tw...\n",
      "Extracted text from page 151: Stochastic\tGradient\tDescent\n",
      "\n",
      "As\twe\tmentioned\tbefore,\toften\twe’ll\tbe\tusing\tgradient\tdescent\tto\tchoose...\n",
      "Extracted text from page 152: def\tmaximize_stochastic(target_fn,\tgradient_fn,\tx,\ty,\ttheta_0,\talpha_0=0.01):\n",
      "\t\t\t\treturn\tminimize_st...\n",
      "Extracted text from page 153: For\tFurther\tExploration\n",
      "\n",
      "Keep\treading!\tWe’ll\tbe\tusing\tgradient\tdescent\tto\tsolve\tproblems\tthroughout\t...\n",
      "Extracted text from page 154: ...\n",
      "Extracted text from page 155: Chapter\t9.\tGetting\tData\n",
      "\n",
      "To\twrite\tit,\tit\ttook\tthree\tmonths;\tto\tconceive\tit,\tthree\tminutes;\tto\tcollec...\n",
      "Extracted text from page 156: stdin\tand\tstdout\n",
      "\n",
      "If\tyou\trun\tyour\tPython\tscripts\tat\tthe\tcommand\tline,\tyou\tcan\tpipe\tdata\tthrough\tthem...\n",
      "Extracted text from page 157: import\tsys\n",
      "from\tcollections\timport\tCounter\n",
      "\n",
      "#\tpass\tin\tnumber\tof\twords\tas\tfirst\targument\n",
      "try:\n",
      "\t\t\t\tnum...\n",
      "Extracted text from page 158: Reading\tFiles\n",
      "\n",
      "You\tcan\talso\texplicitly\tread\tfrom\tand\twrite\tto\tfiles\tdirectly\tin\tyour\tcode.\tPython\tma...\n",
      "Extracted text from page 159: The\tBasics\tof\tText\tFiles\n",
      "\n",
      "The\tfirst\tstep\tto\tworking\twith\ta\ttext\tfile\tis\tto\tobtain\ta\tfile\tobject\tusin...\n",
      "Extracted text from page 160: Delimited\tFiles\n",
      "\n",
      "The\thypothetical\temail\taddresses\tfile\twe\tjust\tprocessed\thad\tone\taddress\tper\tline.\tM...\n",
      "Extracted text from page 161: Even\tif\tyour\tfile\tdoesn’t\thave\theaders\tyou\tcan\tstill\tuse\tDictReader\tby\tpassing\tit\tthe\tkeys\n",
      "as\ta\tfiel...\n",
      "Extracted text from page 162: Scraping\tthe\tWeb\n",
      "\n",
      "Another\tway\tto\tget\tdata\tis\tby\tscraping\tit\tfrom\tweb\tpages.\tFetching\tweb\tpages,\tit\tt...\n",
      "Extracted text from page 163: HTML\tand\tthe\tParsing\tThereof\n",
      "\n",
      "Pages\ton\tthe\tWeb\tare\twritten\tin\tHTML,\tin\twhich\ttext\tis\t(ideally)\tmarke...\n",
      "Extracted text from page 164: first_paragraph_text\t=\tsoup.p.text\n",
      "first_paragraph_words\t=\tsoup.p.text.split()\n",
      "\n",
      "And\tyou\tcan\textract\t...\n",
      "Extracted text from page 165: Example:\tO’Reilly\tBooks\tAbout\tData\n",
      "\n",
      "A\tpotential\tinvestor\tin\tDataSciencester\tthinks\tdata\tis\tjust\ta\tfa...\n",
      "Extracted text from page 166: \t\t\t\t\t\t\t\t<img\tsrc=\"...\"/>\n",
      "\t\t\t\t\t\t</a>\n",
      "\t\t\t\t</div>\n",
      "\t\t</div>\n",
      "\t\t<div\tclass=\"widthchange\">\n",
      "\t\t\t\t<div\tclass=\"...\n",
      "Extracted text from page 167: isbn_link\t=\ttd.find(\"div\",\t\"thumbheader\").a.get(\"href\")\n",
      "\n",
      "#\tre.match\tcaptures\tthe\tpart\tof\tthe\tregex\ti...\n",
      "Extracted text from page 168: \t\t\t\treturn\tint(book[\"date\"].split()[1])\n",
      "\n",
      "#\t2014\tis\tthe\tlast\tcomplete\tyear\tof\tdata\t(when\tI\tran\tthis)\n",
      "...\n",
      "Extracted text from page 169: Using\tAPIs\n",
      "\n",
      "Many\twebsites\tand\tweb\tservices\tprovide\tapplication\tprogramming\tinterfaces\t(APIs),\n",
      "which\t...\n",
      "Extracted text from page 170: JSON\t(and\tXML)\n",
      "\n",
      "Because\tHTTP\tis\ta\tprotocol\tfor\ttransferring\ttext,\tthe\tdata\tyou\trequest\tthrough\ta\tweb...\n",
      "Extracted text from page 171: Using\tan\tUnauthenticated\tAPI\n",
      "\n",
      "Most\tAPIs\tthese\tdays\trequire\tyou\tto\tfirst\tauthenticate\tyourself\tin\tord...\n",
      "Extracted text from page 172: debug\twhy\tsomeone\telse’s\tisn’t\tworking),\tso\tit’s\tgood\tto\tknow\tsome\tof\tthe\tdetails.\n",
      "\n",
      "...\n",
      "Extracted text from page 173: Finding\tAPIs\n",
      "\n",
      "If\tyou\tneed\tdata\tfrom\ta\tspecific\tsite,\tlook\tfor\ta\tdevelopers\tor\tAPI\tsection\tof\tthe\tsit...\n",
      "Extracted text from page 174: Example:\tUsing\tthe\tTwitter\tAPIs\n",
      "\n",
      "Twitter\tis\ta\tfantastic\tsource\tof\tdata\tto\twork\twith.\tYou\tcan\tuse\tit\t...\n",
      "Extracted text from page 175: Getting\tCredentials\n",
      "\n",
      "In\torder\tto\tuse\tTwitter’s\tAPIs,\tyou\tneed\tto\tget\tsome\tcredentials\t(for\twhich\tyou...\n",
      "Extracted text from page 176: from\ttwython\timport\tTwython\n",
      "\n",
      "twitter\t=\tTwython(CONSUMER_KEY,\tCONSUMER_SECRET)\n",
      "\n",
      "#\tsearch\tfor\ttweets\tc...\n",
      "Extracted text from page 177: \t\t\t\t\t\t\t\tprint\tstatus_code,\tdata\n",
      "\t\t\t\t\t\t\t\tself.disconnect()\n",
      "\n",
      "MyStreamer\twill\tconnect\tto\tthe\tTwitter\tst...\n",
      "Extracted text from page 178: For\tFurther\tExploration\n",
      "\n",
      "pandas\tis\tthe\tprimary\tlibrary\tthat\tdata\tscience\ttypes\tuse\tfor\tworking\twith\t...\n",
      "Extracted text from page 179: ...\n",
      "Extracted text from page 180: Chapter\t10.\tWorking\twith\tData\n",
      "\n",
      "Experts\toften\tpossess\tmore\tdata\tthan\tjudgment.\n",
      "\n",
      "Colin\tPowell\n",
      "\n",
      "Working...\n",
      "Extracted text from page 181: Exploring\tYour\tData\n",
      "\n",
      "After\tyou’ve\tidentified\tthe\tquestions\tyou’re\ttrying\tto\tanswer\tand\thave\tgotten\ty...\n",
      "Extracted text from page 182: Exploring\tOne-Dimensional\tData\n",
      "\n",
      "The\tsimplest\tcase\tis\twhen\tyou\thave\ta\tone-dimensional\tdata\tset,\twhich...\n",
      "Extracted text from page 183: Figure\t10-1.\tHistogram\tof\tuniform\n",
      "\n",
      "...\n",
      "Extracted text from page 184: Two\tDimensions\n",
      "\n",
      "Now\timagine\tyou\thave\ta\tdata\tset\twith\ttwo\tdimensions.\tMaybe\tin\taddition\tto\tdaily\n",
      "minu...\n",
      "Extracted text from page 185: plt.title(\"Very\tDifferent\tJoint\tDistributions\")\n",
      "plt.show()\n",
      "\n",
      "This\tdifference\twould\talso\tbe\tapparent\ti...\n",
      "Extracted text from page 186: Many\tDimensions\n",
      "\n",
      "With\tmany\tdimensions,\tyou’d\tlike\tto\tknow\thow\tall\tthe\tdimensions\trelate\tto\tone\tanoth...\n",
      "Extracted text from page 187: Figure\t10-4.\tScatterplot\tmatrix\n",
      "\n",
      "Looking\tat\tthe\tscatterplots,\tyou\tcan\tsee\tthat\tseries\t1\tis\tvery\tnega...\n",
      "Extracted text from page 188: Cleaning\tand\tMunging\n",
      "\n",
      "Real-world\tdata\tis\tdirty.\tOften\tyou’ll\thave\tto\tdo\tsome\twork\ton\tit\tbefore\tyou\tc...\n",
      "Extracted text from page 189: with\topen(\"comma_delimited_stock_prices.csv\",\t\"rb\")\tas\tf:\n",
      "\t\t\t\treader\t=\tcsv.reader(f)\n",
      "\t\t\t\tfor\tline\tin...\n",
      "Extracted text from page 190: Manipulating\tData\n",
      "\n",
      "One\tof\tthe\tmost\timportant\tskills\tof\ta\tdata\tscientist\tis\tmanipulating\tdata.\tIt’s\tm...\n",
      "Extracted text from page 191: def\tpicker(field_name):\n",
      "\t\t\t\t\"\"\"returns\ta\tfunction\tthat\tpicks\ta\tfield\tout\tof\ta\tdict\"\"\"\n",
      "\t\t\t\treturn\tlam...\n",
      "Extracted text from page 192: #\tkey\tis\tsymbol,\tvalue\tis\tlist\tof\t\"change\"\tdicts\n",
      "changes_by_symbol\t=\tgroup_by(picker(\"symbol\"),\tdata...\n",
      "Extracted text from page 193: Rescaling\n",
      "\n",
      "Many\ttechniques\tare\tsensitive\tto\tthe\tscale\tof\tyour\tdata.\tFor\texample,\timagine\tthat\tyou\n",
      "ha...\n",
      "Extracted text from page 194: def\trescale(data_matrix):\n",
      "\t\t\t\t\"\"\"rescales\tthe\tinput\tdata\tso\tthat\teach\tcolumn\n",
      "\t\t\t\thas\tmean\t0\tand\tstan...\n",
      "Extracted text from page 195: Dimensionality\tReduction\n",
      "\n",
      "Sometimes\tthe\t“actual”\t(or\tuseful)\tdimensions\tof\tthe\tdata\tmight\tnot\tcorres...\n",
      "Extracted text from page 196: (If\twe\tdon’t\tdo\tthis,\tour\ttechniques\tare\tlikely\tto\tidentify\tthe\tmean\titself\trather\tthan\tthe\n",
      "variatio...\n",
      "Extracted text from page 197: We’d\tlike\tto\tfind\tthe\tdirection\tthat\tmaximizes\tthis\tvariance.\tWe\tcan\tdo\tthis\tusing\tgradient\n",
      "descent,...\n",
      "Extracted text from page 198: Figure\t10-7.\tFirst\tprincipal\tcomponent\n",
      "\n",
      "Once\twe’ve\tfound\tthe\tdirection\tthat’s\tthe\tfirst\tprincipal\tco...\n",
      "Extracted text from page 199: Figure\t10-8.\tData\tafter\tremoving\tfirst\tprincipal\tcomponent\n",
      "\n",
      "At\tthat\tpoint,\twe\tcan\tfind\tthe\tnext\tprin...\n",
      "Extracted text from page 200: Figure\t10-9.\tFirst\ttwo\tprincipal\tcomponents\n",
      "\n",
      "Second,\tafter\textracting\ta\tlow-dimensional\trepresentati...\n",
      "Extracted text from page 201: For\tFurther\tExploration\n",
      "\n",
      "As\twe\tmentioned\tat\tthe\tend\tof\tChapter\t9,\tpandas\tis\tprobably\tthe\tprimary\tPyt...\n",
      "Extracted text from page 202: ...\n",
      "Extracted text from page 203: Chapter\t11.\tMachine\tLearning\n",
      "\n",
      "I\tam\talways\tready\tto\tlearn\talthough\tI\tdo\tnot\talways\tlike\tbeing\ttaught....\n",
      "Extracted text from page 204: Modeling\n",
      "\n",
      "Before\twe\tcan\ttalk\tabout\tmachine\tlearning\twe\tneed\tto\ttalk\tabout\tmodels.\n",
      "\n",
      "What\tis\ta\tmodel?\t...\n",
      "Extracted text from page 205: What\tIs\tMachine\tLearning?\n",
      "\n",
      "Everyone\thas\ther\town\texact\tdefinition,\tbut\twe’ll\tuse\tmachine\tlearning\tto\t...\n",
      "Extracted text from page 206: Overfitting\tand\tUnderfitting\n",
      "\n",
      "A\tcommon\tdanger\tin\tmachine\tlearning\tis\toverfitting\t—\tproducing\ta\tmodel...\n",
      "Extracted text from page 207: the\tdata\tthey\twere\ttrained\ton.\tSo\thow\tdo\twe\tmake\tsure\tour\tmodels\taren’t\ttoo\tcomplex?\n",
      "The\tmost\tfundam...\n",
      "Extracted text from page 208: In\tsuch\ta\tsituation,\tyou\tshould\tsplit\tthe\tdata\tinto\tthree\tparts:\ta\ttraining\tset\tfor\tbuilding\n",
      "models,...\n",
      "Extracted text from page 209: Correctness\n",
      "\n",
      "When\tI’m\tnot\tdoing\tdata\tscience,\tI\tdabble\tin\tmedicine.\tAnd\tin\tmy\tspare\ttime\tI’ve\tcome\n",
      "u...\n",
      "Extracted text from page 210: We\tcan\tthen\tuse\tthese\tto\tcompute\tvarious\tstatistics\tabout\tmodel\tperformance.\tFor\n",
      "example,\taccuracy\ti...\n",
      "Extracted text from page 211: test’s\trecall\t(since\tfewer\tand\tfewer\tof\tthe\teventual\tdisease-sufferers\twill\tmeet\tthe\n",
      "threshhold).\tIn...\n",
      "Extracted text from page 212: The\tBias-Variance\tTrade-off\n",
      "\n",
      "Another\tway\tof\tthinking\tabout\tthe\toverfitting\tproblem\tis\tas\ta\ttrade-off...\n",
      "Extracted text from page 213: Figure\t11-2.\tReducing\tvariance\twith\tmore\tdata\n",
      "\n",
      "In\tFigure\t11-2,\twe\tfit\ta\tdegree\t9\tpolynomial\tto\tdiffe...\n",
      "Extracted text from page 214: Feature\tExtraction\tand\tSelection\n",
      "\n",
      "As\twe\tmentioned,\twhen\tyour\tdata\tdoesn’t\thave\tenough\tfeatures,\tyour...\n",
      "Extracted text from page 215: How\tdo\twe\tchoose\tfeatures?\tThat’s\twhere\ta\tcombination\tof\texperience\tand\tdomain\n",
      "expertise\tcomes\tinto\t...\n",
      "Extracted text from page 216: For\tFurther\tExploration\n",
      "\n",
      "Keep\treading!\tThe\tnext\tseveral\tchapters\tare\tabout\tdifferent\tfamilies\tof\tmac...\n",
      "Extracted text from page 217: ...\n",
      "Extracted text from page 218: Chapter\t12.\tk-Nearest\tNeighbors\n",
      "\n",
      "If\tyou\twant\tto\tannoy\tyour\tneighbors,\ttell\tthe\ttruth\tabout\tthem.\n",
      "\n",
      "Pi...\n",
      "Extracted text from page 219: The\tModel\n",
      "\n",
      "Nearest\tneighbors\tis\tone\tof\tthe\tsimplest\tpredictive\tmodels\tthere\tis.\tIt\tmakes\tno\n",
      "mathemat...\n",
      "Extracted text from page 220: We’ll\timplement\tthe\tthird:\n",
      "\n",
      "def\tmajority_vote(labels):\n",
      "\t\t\t\t\"\"\"assumes\tthat\tlabels\tare\tordered\tfrom\tn...\n",
      "Extracted text from page 221: Example:\tFavorite\tLanguages\n",
      "\n",
      "The\tresults\tof\tthe\tfirst\tDataSciencester\tuser\tsurvey\tare\tback,\tand\twe’v...\n",
      "Extracted text from page 222: Figure\t12-1.\tFavorite\tprogramming\tlanguages\n",
      "\n",
      "NOTE\n",
      "\n",
      "You\tmay\thave\tnoticed\tthe\tcall\tto\tplot_state_borde...\n",
      "Extracted text from page 223: \t\t\t\t\t\t\t\tif\tpredicted_language\t==\tactual_language:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tnum_correct\t+=\t1\n",
      "\n",
      "\t\t\t\tprint\tk,\t\"neighb...\n",
      "Extracted text from page 224: Figure\t12-2.\t1-Nearest\tneighbor\tprogramming\tlanguages\n",
      "\n",
      "...\n",
      "Extracted text from page 225: The\tCurse\tof\tDimensionality\n",
      "\n",
      "k-nearest\tneighbors\truns\tinto\ttrouble\tin\thigher\tdimensions\tthanks\tto\tth...\n",
      "Extracted text from page 226: Figure\t12-4.\t5-Nearest\tneighbor\tprogramming\tlanguages\n",
      "\n",
      "For\tevery\tdimension\tfrom\t1\tto\t100,\twe’ll\tcomp...\n",
      "Extracted text from page 227: Figure\t12-5.\tThe\tcurse\tof\tdimensionality\n",
      "\n",
      "As\tthe\tnumber\tof\tdimensions\tincreases,\tthe\taverage\tdistanc...\n",
      "Extracted text from page 228: Figure\t12-6.\tThe\tcurse\tof\tdimensionality\tagain\n",
      "\n",
      "In\tlow-dimensional\tdata\tsets,\tthe\tclosest\tpoints\tten...\n",
      "Extracted text from page 229: Figure\t12-7.\tFifty\trandom\tpoints\tin\tone\tdimension\n",
      "\n",
      "If\tyou\tpick\t50\trandom\tpoints\tin\tthe\tunit\tsquare,\t...\n",
      "Extracted text from page 230: Figure\t12-8.\tFifty\trandom\tpoints\tin\ttwo\tdimensions\n",
      "\n",
      "And\tin\tthree\tdimensions\tless\tstill\t(Figure\t12-9)...\n",
      "Extracted text from page 231: Figure\t12-9.\tFifty\trandom\tpoints\tin\tthree\tdimensions\n",
      "\n",
      "...\n",
      "Extracted text from page 232: For\tFurther\tExploration\n",
      "\n",
      "scikit-learn\thas\tmany\tnearest\tneighbor\tmodels.\n",
      "\n",
      "...\n",
      "Extracted text from page 233: ...\n",
      "Extracted text from page 234: Chapter\t13.\tNaive\tBayes\n",
      "\n",
      "It\tis\twell\tfor\tthe\theart\tto\tbe\tnaive\tand\tfor\tthe\tmind\tnot\tto\tbe.\n",
      "\n",
      "Anatole\tF...\n",
      "Extracted text from page 235: A\tReally\tDumb\tSpam\tFilter\n",
      "\n",
      "Imagine\ta\t“universe”\tthat\tconsists\tof\treceiving\ta\tmessage\tchosen\trandomly...\n",
      "Extracted text from page 236: A\tMore\tSophisticated\tSpam\tFilter\n",
      "\n",
      "Imagine\tnow\tthat\twe\thave\ta\tvocabulary\tof\tmany\twords\t\n",
      "the\trealm\tof\t...\n",
      "Extracted text from page 237: ,\tthe\n",
      "The\tonly\tchallenge\tleft\tis\tcoming\tup\twith\testimates\tfor\t\n",
      "probabilities\tthat\ta\tspam\tmessage\t(or...\n",
      "Extracted text from page 238: Implementation\n",
      "\n",
      "Now\twe\thave\tall\tthe\tpieces\twe\tneed\tto\tbuild\tour\tclassifier.\tFirst,\tlet’s\tcreate\ta\tsi...\n",
      "Extracted text from page 239: \t\t\t\t\t\t\t\t\t\t\t\tlog_prob_if_spam\t+=\tmath.log(1.0\t-\tprob_if_spam)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tlog_prob_if_not_spam\t+=\tmat...\n",
      "Extracted text from page 240: Testing\tOur\tModel\n",
      "\n",
      "A\tgood\t(if\tsomewhat\told)\tdata\tset\tis\tthe\tSpamAssassin\tpublic\tcorpus.\tWe’ll\tlook\ta...\n",
      "Extracted text from page 241: #\tsort\tby\tspam_probability\tfrom\tsmallest\tto\tlargest\n",
      "classified.sort(key=lambda\trow:\trow[2])\n",
      "\n",
      "#\tthe\th...\n",
      "Extracted text from page 242: Creating\ta\tgood\tstemmer\tfunction\tis\thard.\tPeople\tfrequently\tuse\tthe\tPorter\tStemmer.\n",
      "\n",
      "Although\tour\tfe...\n",
      "Extracted text from page 243: For\tFurther\tExploration\n",
      "\n",
      "Paul\tGraham’s\tarticles\t“A\tPlan\tfor\tSpam”\tand\t“Better\tBayesian\tFiltering”\t(a...\n",
      "Extracted text from page 244: ...\n",
      "Extracted text from page 245: Chapter\t14.\tSimple\tLinear\tRegression\n",
      "\n",
      "Art,\tlike\tmorality,\tconsists\tin\tdrawing\tthe\tline\tsomewhere.\n",
      "\n",
      "G...\n",
      "Extracted text from page 246: The\tModel\n",
      "\n",
      "Recall\tthat\twe\twere\tinvestigating\tthe\trelationship\tbetween\ta\tDataSciencester\tuser’s\n",
      "numbe...\n",
      "Extracted text from page 247: \t\t\t\t\"\"\"given\ttraining\tvalues\tfor\tx\tand\ty,\n",
      "\t\t\t\tfind\tthe\tleast-squares\tvalues\tof\talpha\tand\tbeta\"\"\"\n",
      "\t\t\t...\n",
      "Extracted text from page 248: Figure\t14-1.\tOur\tsimple\tlinear\tmodel\n",
      "\n",
      "Of\tcourse,\twe\tneed\ta\tbetter\tway\tto\tfigure\tout\thow\twell\twe’ve\tf...\n",
      "Extracted text from page 249: Clearly,\tthe\tleast\tsquares\tmodel\tmust\tbe\tat\tleast\tas\tgood\tas\tthat\tone,\twhich\tmeans\tthat\tthe\n",
      "sum\tof\tt...\n",
      "Extracted text from page 250: Using\tGradient\tDescent\n",
      "\n",
      "If\twe\twrite\ttheta\t=\t[alpha,\tbeta],\tthen\twe\tcan\talso\tsolve\tthis\tusing\tgradien...\n",
      "Extracted text from page 251: Maximum\tLikelihood\tEstimation\n",
      "\n",
      "Why\tchoose\tleast\tsquares?\tOne\tjustification\tinvolves\tmaximum\tlikeliho...\n",
      "Extracted text from page 252: For\tFurther\tExploration\n",
      "\n",
      "Continue\treading\tabout\tmultiple\tregression\tin\tChapter\t15!\n",
      "\n",
      "...\n",
      "Extracted text from page 253: ...\n",
      "Extracted text from page 254: Chapter\t15.\tMultiple\tRegression\n",
      "\n",
      "I\tdon’t\tlook\tat\ta\tproblem\tand\tput\tvariables\tin\tthere\tthat\tdon’t\taff...\n",
      "Extracted text from page 255: The\tModel\n",
      "\n",
      "Recall\tthat\tin\tChapter\t14\twe\tfit\ta\tmodel\tof\tthe\tform:\n",
      "\n",
      "Now\timagine\tthat\teach\tinput\t\n",
      "\n",
      "\tis\t...\n",
      "Extracted text from page 256: Further\tAssumptions\tof\tthe\tLeast\tSquares\tModel\n",
      "\n",
      "There\tare\ta\tcouple\tof\tfurther\tassumptions\tthat\tare\tr...\n",
      "Extracted text from page 257: decreasing\tour\testimate\tof\t\n",
      "\tis\tsmaller\tthan\n",
      "the\t“actual”\tvalue.\tThat\tis,\tin\tthis\tcase\tthe\tsingle-va...\n",
      "Extracted text from page 258: Fitting\tthe\tModel\n",
      "\n",
      "As\twe\tdid\tin\tthe\tsimple\tlinear\tmodel,\twe’ll\tchoose\tbeta\tto\tminimize\tthe\tsum\tof\tsq...\n",
      "Extracted text from page 259: Interpreting\tthe\tModel\n",
      "\n",
      "You\tshould\tthink\tof\tthe\tcoefficients\tof\tthe\tmodel\tas\trepresenting\tall-else-b...\n",
      "Extracted text from page 260: Goodness\tof\tFit\n",
      "\n",
      "Again\twe\tcan\tlook\tat\tthe\tR-squared,\twhich\thas\tnow\tincreased\tto\t0.68:\n",
      "\n",
      "def\tmultiple_...\n",
      "Extracted text from page 261: Digression:\tThe\tBootstrap\n",
      "\n",
      "Imagine\twe\thave\ta\tsample\tof\tn\tdata\tpoints,\tgenerated\tby\tsome\t(unknown\tto\t...\n",
      "Extracted text from page 262: would\tbe\tpretty\teasy\tto\tfigure\tout\tby\tmanually\tinspecting\tthe\tdata,\tbut\tin\tgeneral\tthat\n",
      "won’t\tbe\ttru...\n",
      "Extracted text from page 263: Standard\tErrors\tof\tRegression\tCoefficients\n",
      "\n",
      "We\tcan\ttake\tthe\tsame\tapproach\tto\testimating\tthe\tstandard...\n",
      "Extracted text from page 264: However,\tas\tthe\tdegrees\tof\tfreedom\tget\tlarge,\tthe\tt-distribution\tgets\tcloser\tand\tcloser\tto\ta\n",
      "standar...\n",
      "Extracted text from page 265: Regularization\n",
      "\n",
      "In\tpractice,\tyou’d\toften\tlike\tto\tapply\tlinear\tregression\tto\tdata\tsets\twith\tlarge\tnum...\n",
      "Extracted text from page 266: beta_0_01\t=\testimate_beta_ridge(x,\tdaily_minutes_good,\talpha=0.01)\n",
      "#\t[30.6,\t0.97,\t-1.86,\t0.89]\n",
      "dot(b...\n",
      "Extracted text from page 267: For\tFurther\tExploration\n",
      "\n",
      "Regression\thas\ta\trich\tand\texpansive\ttheory\tbehind\tit.\tThis\tis\tanother\tplace...\n",
      "Extracted text from page 268: ...\n",
      "Extracted text from page 269: Chapter\t16.\tLogistic\tRegression\n",
      "\n",
      "A\tlot\tof\tpeople\tsay\tthere’s\ta\tfine\tline\tbetween\tgenius\tand\tinsanity...\n",
      "Extracted text from page 270: The\tProblem\n",
      "\n",
      "We\thave\tan\tanonymized\tdata\tset\tof\tabout\t200\tusers,\tcontaining\teach\tuser’s\tsalary,\ther\n",
      "y...\n",
      "Extracted text from page 271: beta\t=\testimate_beta(rescaled_x,\ty)\t\t#\t[0.26,\t0.43,\t-0.43]\n",
      "predictions\t=\t[predict(x_i,\tbeta)\tfor\tx_i...\n",
      "Extracted text from page 272: What\twe’d\tlike\tinstead\tis\tfor\tlarge\tpositive\tvalues\tof\tdot(x_i,\tbeta)\tto\tcorrespond\tto\n",
      "probabilities...\n",
      "Extracted text from page 273: The\tLogistic\tFunction\n",
      "\n",
      "In\tthe\tcase\tof\tlogistic\tregression,\twe\tuse\tthe\tlogistic\tfunction,\tpictured\tin...\n",
      "Extracted text from page 274: which\tended\tup\tchoosing\tthe\t\n",
      "\n",
      "\tthat\tmaximized\tthe\tlikelihood\tof\tthe\tdata.\n",
      "\n",
      "Here\tthe\ttwo\taren’t\tequiv...\n",
      "Extracted text from page 275: def\tlogistic_log_gradient_i(x_i,\ty_i,\tbeta):\n",
      "\t\t\t\t\"\"\"the\tgradient\tof\tthe\tlog\tlikelihood\n",
      "\t\t\t\tcorrespon...\n",
      "Extracted text from page 276: Applying\tthe\tModel\n",
      "\n",
      "We’ll\twant\tto\tsplit\tour\tdata\tinto\ta\ttraining\tset\tand\ta\ttest\tset:\n",
      "\n",
      "random.seed(0)...\n",
      "Extracted text from page 277: Goodness\tof\tFit\n",
      "\n",
      "We\thaven’t\tyet\tused\tthe\ttest\tdata\tthat\twe\theld\tout.\tLet’s\tsee\twhat\thappens\tif\twe\tpr...\n",
      "Extracted text from page 278: Figure\t16-4.\tLogistic\tregression\tpredicted\tversus\tactual\n",
      "\n",
      "...\n",
      "Extracted text from page 279: Support\tVector\tMachines\n",
      "\n",
      "The\tset\tof\tpoints\twhere\tdot(beta_hat,\tx_i)\tequals\t0\tis\tthe\tboundary\tbetween...\n",
      "Extracted text from page 280: Figure\t16-6.\tA\tseparating\thyperplane\n",
      "\n",
      "It’s\tclear\tthat\tthere’s\tno\thyperplane\tthat\tseparates\tthe\tposit...\n",
      "Extracted text from page 281: Figure\t16-7.\tA\tnonseparable\tone-dimensional\tdata\tset\n",
      "\n",
      "It’s\thard\t(and\tprobably\tnot\ta\tgood\tidea)\tto\tus...\n",
      "Extracted text from page 282: Figure\t16-8.\tData\tset\tbecomes\tseparable\tin\thigher\tdimensions\n",
      "\n",
      "...\n",
      "Extracted text from page 283: For\tFurther\tInvestigation\n",
      "\n",
      "scikit-learn\thas\tmodules\tfor\tboth\tLogistic\tRegression\tand\tSupport\tVector\t...\n",
      "Extracted text from page 284: ...\n",
      "Extracted text from page 285: Chapter\t17.\tDecision\tTrees\n",
      "\n",
      "A\ttree\tis\tan\tincomprehensible\tmystery.\n",
      "\n",
      "Jim\tWoodring\n",
      "\n",
      "DataSciencester’s\t...\n",
      "Extracted text from page 286: What\tIs\ta\tDecision\tTree?\n",
      "\n",
      "A\tdecision\ttree\tuses\ta\ttree\tstructure\tto\trepresent\ta\tnumber\tof\tpossible\tde...\n",
      "Extracted text from page 287: Figure\t17-1.\tA\t“guess\tthe\tanimal”\tdecision\ttree\n",
      "\n",
      "Decision\ttrees\thave\ta\tlot\tto\trecommend\tthem.\tThey’r...\n",
      "Extracted text from page 288: Entropy\n",
      "\n",
      "In\torder\tto\tbuild\ta\tdecision\ttree,\twe\twill\tneed\tto\tdecide\twhat\tquestions\tto\task\tand\tin\twhat...\n",
      "Extracted text from page 289: Figure\t17-2.\tA\tgraph\tof\t-p\tlog\tp\n",
      "\n",
      "This\tmeans\tthe\tentropy\twill\tbe\tsmall\twhen\tevery\t\n",
      "the\tdata\tis\tin\ta\t...\n",
      "Extracted text from page 290: \t\t\t\treturn\tentropy(probabilities)\n",
      "\n",
      "...\n",
      "Extracted text from page 291: The\tEntropy\tof\ta\tPartition\n",
      "\n",
      "What\twe’ve\tdone\tso\tfar\tis\tcompute\tthe\tentropy\t(think\t“uncertainty”)\tof\ta...\n",
      "Extracted text from page 292: Creating\ta\tDecision\tTree\n",
      "\n",
      "The\tVP\tprovides\tyou\twith\tthe\tinterviewee\tdata,\tconsisting\tof\t(per\tyour\tspe...\n",
      "Extracted text from page 293: the\tpartitioning:\n",
      "\n",
      "def\tpartition_by(inputs,\tattribute):\n",
      "\t\t\t\t\"\"\"each\tinput\tis\ta\tpair\t(attribute_dict,...\n",
      "Extracted text from page 294: Figure\t17-3.\tThe\tdecision\ttree\tfor\thiring\n",
      "\n",
      "...\n",
      "Extracted text from page 295: Putting\tIt\tAll\tTogether\n",
      "\n",
      "Now\tthat\twe’ve\tseen\thow\tthe\talgorithm\tworks,\twe\twould\tlike\tto\timplement\tit\t...\n",
      "Extracted text from page 296: \t\t\t\t#\tif\tthis\tis\tour\tfirst\tpass,\n",
      "\t\t\t\t#\tall\tkeys\tof\tthe\tfirst\tinput\tare\tsplit\tcandidates\n",
      "\t\t\t\tif\tsplit...\n",
      "Extracted text from page 297: Random\tForests\n",
      "\n",
      "Given\thow\tclosely\tdecision\ttrees\tcan\tfit\tthemselves\tto\ttheir\ttraining\tdata,\tit’s\tnot...\n",
      "Extracted text from page 298: For\tFurther\tExploration\n",
      "\n",
      "scikit-learn\thas\tmany\tDecision\tTree\tmodels.\tIt\talso\thas\tan\tensemble\tmodule\t...\n",
      "Extracted text from page 299: ...\n",
      "Extracted text from page 300: Chapter\t18.\tNeural\tNetworks\n",
      "\n",
      "I\tlike\tnonsense;\tit\twakes\tup\tthe\tbrain\tcells.\n",
      "\n",
      "Dr.\tSeuss\n",
      "\n",
      "An\tartificial...\n",
      "Extracted text from page 301: Perceptrons\n",
      "\n",
      "Pretty\tmuch\tthe\tsimplest\tneural\tnetwork\tis\tthe\tperceptron,\twhich\tapproximates\ta\tsingle\n",
      "...\n",
      "Extracted text from page 302: Figure\t18-1.\tDecision\tspace\tfor\ta\ttwo-input\tperceptron\n",
      "\n",
      "And\twe\tcould\tbuild\ta\tNOT\tgate\t(which\thas\tone...\n",
      "Extracted text from page 303: Feed-Forward\tNeural\tNetworks\n",
      "\n",
      "The\ttopology\tof\tthe\tbrain\tis\tenormously\tcomplicated,\tso\tit’s\tcommon\tto...\n",
      "Extracted text from page 304: Why\tuse\tsigmoid\tinstead\tof\tthe\tsimpler\tstep_function?\tIn\torder\tto\ttrain\ta\tneural\n",
      "network,\twe’ll\tneed...\n",
      "Extracted text from page 305: \t\t\t\t\t\t\t\tprint\tx,\ty,\tfeed_forward(xor_network,[x,\ty])[-1]\n",
      "\n",
      "#\t0\t0\t[9.38314668300676e-14]\n",
      "#\t0\t1\t[0.9999...\n",
      "Extracted text from page 306: Backpropagation\n",
      "\n",
      "Usually\twe\tdon’t\tbuild\tneural\tnetworks\tby\thand.\tThis\tis\tin\tpart\tbecause\twe\tuse\tthem...\n",
      "Extracted text from page 307: \t\t\t\t\t\t\t\t\t\t\t\thidden_neuron[j]\t-=\thidden_deltas[i]\t*\tinput\n",
      "\n",
      "This\tis\tpretty\tmuch\tdoing\tthe\tsame\tthing\ta...\n",
      "Extracted text from page 308: Example:\tDefeating\ta\tCAPTCHA\n",
      "\n",
      "To\tmake\tsure\tthat\tpeople\tregistering\tfor\tyour\tsite\tare\tactually\tpeople...\n",
      "Extracted text from page 309: #\tthe\tnetwork\tstarts\tout\twith\trandom\tweights\n",
      "network\t=\t[hidden_layer,\toutput_layer]\n",
      "\n",
      "And\twe\tcan\ttrai...\n",
      "Extracted text from page 310: images\tpixel\tby\tpixel.\tNormally\tthis\tisn’t\tall\tthat\tuseful\tfor\tdata\tscience,\tbut\there\tit’s\ta\n",
      "good\tch...\n",
      "Extracted text from page 311: lines,\tand\tthe\tlast\thidden\tneuron\tseems\tto\t“like”\tthe\tcenter\trow\tbut\tnot\tthe\tright\tcolumn.\n",
      "(The\tothe...\n",
      "Extracted text from page 312: For\tFurther\tExploration\n",
      "\n",
      "Coursera\thas\ta\tfree\tcourse\ton\tNeural\tNetworks\tfor\tMachine\tLearning.\tAs\tI\twr...\n",
      "Extracted text from page 313: ...\n",
      "Extracted text from page 314: Chapter\t19.\tClustering\n",
      "\n",
      "Where\twe\tsuch\tclusters\thad\n",
      "\n",
      "As\tmade\tus\tnobly\twild,\tnot\tmad\n",
      "\n",
      "Robert\tHerrick\n",
      "\n",
      "...\n",
      "Extracted text from page 315: The\tIdea\n",
      "\n",
      "Whenever\tyou\tlook\tat\tsome\tsource\tof\tdata,\tit’s\tlikely\tthat\tthe\tdata\twill\tsomehow\tform\n",
      "clus...\n",
      "Extracted text from page 316: The\tModel\n",
      "\n",
      "For\tus,\teach\tinput\twill\tbe\ta\tvector\tin\td-dimensional\tspace\t(which,\tas\tusual,\twe\twill\n",
      "repr...\n",
      "Extracted text from page 317: \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\treturn\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t#\tOtherwise\tkeep\tthe\tnew\tassignments,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tassignments\t=\t...\n",
      "Extracted text from page 318: Example:\tMeetups\n",
      "\n",
      "To\tcelebrate\tDataSciencester’s\tgrowth,\tyour\tVP\tof\tUser\tRewards\twants\tto\torganize\n",
      "s...\n",
      "Extracted text from page 319: meetups.\n",
      "\n",
      "“No\tproblem,”\tyou\tsay:\n",
      "\n",
      "random.seed(0)\n",
      "clusterer\t=\tKMeans(2)\n",
      "clusterer.train(inputs)\n",
      "print...\n",
      "Extracted text from page 320: Figure\t19-3.\tUser\tlocations\tgrouped\tinto\ttwo\tclusters\n",
      "\n",
      "...\n",
      "Extracted text from page 321: Choosing\tk\n",
      "\n",
      "In\tthe\tprevious\texample,\tthe\tchoice\tof\tk\twas\tdriven\tby\tfactors\toutside\tof\tour\tcontrol.\tI...\n",
      "Extracted text from page 322: Figure\t19-4.\tChoosing\ta\tk\n",
      "\n",
      "Looking\tat\tFigure\t19-4,\tthis\tmethod\tagrees\twith\tour\toriginal\teyeballing\tt...\n",
      "Extracted text from page 323: Example:\tClustering\tColors\n",
      "\n",
      "The\tVP\tof\tSwag\thas\tdesigned\tattractive\tDataSciencester\tstickers\tthat\the’...\n",
      "Extracted text from page 324: new_img\t=\t[[recolor(pixel)\tfor\tpixel\tin\trow]\t\t\t#\trecolor\tthis\trow\tof\tpixels\n",
      "\t\t\t\t\t\t\t\t\t\t\tfor\trow\tin\tim...\n",
      "Extracted text from page 325: Bottom-up\tHierarchical\tClustering\n",
      "\n",
      "An\talternative\tapproach\tto\tclustering\tis\tto\t“grow”\tclusters\tfrom\t...\n",
      "Extracted text from page 326: def\tcluster_distance(cluster1,\tcluster2,\tdistance_agg=min):\n",
      "\t\t\t\t\"\"\"compute\tall\tthe\tpairwise\tdistance...\n",
      "Extracted text from page 327: \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(13,\t[(15,\t[(17,\t[([-11,\t-6],),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t([-12,\t-8]...\n",
      "Extracted text from page 328: \t\t\t\tplt.plot(x,\ty,\tmarker='$'\t+\tstr(i)\t+\t'$',\tcolor='black')\n",
      "\n",
      "plt.title(\"User\tLocations—3\tBottom-Up\t...\n",
      "Extracted text from page 329: Figure\t19-7.\tThree\tbottom-up\tclusters\tusing\tmax\tdistance\n",
      "\n",
      "...\n",
      "Extracted text from page 330: For\tFurther\tExploration\n",
      "\n",
      "scikit-learn\thas\tan\tentire\tmodule\tsklearn.cluster\tthat\tcontains\tseveral\tclu...\n",
      "Extracted text from page 331: ...\n",
      "Extracted text from page 332: Chapter\t20.\tNatural\tLanguage\tProcessing\n",
      "\n",
      "They\thave\tbeen\tat\ta\tgreat\tfeast\tof\tlanguages,\tand\tstolen\tth...\n",
      "Extracted text from page 333: Word\tClouds\n",
      "\n",
      "In\tChapter\t1,\twe\tcomputed\tword\tcounts\tof\tusers’\tinterests.\tOne\tapproach\tto\tvisualizing\n",
      "...\n",
      "Extracted text from page 334: Figure\t20-1.\tBuzzword\tcloud\n",
      "\n",
      "This\tlooks\tneat\tbut\tdoesn’t\treally\ttell\tus\tanything.\tA\tmore\tinteresting...\n",
      "Extracted text from page 335: Figure\t20-2.\tA\tmore\tmeaningful\t(if\tless\tattractive)\tword\tcloud\n",
      "\n",
      "...\n",
      "Extracted text from page 336: n-gram\tModels\n",
      "\n",
      "The\tDataSciencester\tVP\tof\tSearch\tEngine\tMarketing\twants\tto\tcreate\tthousands\tof\tweb\n",
      "pa...\n",
      "Extracted text from page 337: randomly\tchoose\tone\tof\tthese\tto\tbe\tthe\tnext\tword,\tand\twe\trepeat\tthe\tprocess\tuntil\twe\tget\n",
      "to\ta\tperiod...\n",
      "Extracted text from page 338: \t\t\t\tprev\t=\t\".\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#\tand\tprecede\tit\twith\ta\t'.'\n",
      "\t\t\t\tresult\t=\t[current]\n",
      "\t\t\t\twhile\tT...\n",
      "Extracted text from page 339: Grammars\n",
      "\n",
      "A\tdifferent\tapproach\tto\tmodeling\tlanguage\tis\twith\tgrammars,\trules\tfor\tgenerating\n",
      "acceptabl...\n",
      "Extracted text from page 340: How\tdo\twe\timplement\tthis?\tWell,\tto\tstart,\twe’ll\tcreate\ta\tsimple\thelper\tfunction\tto\tidentify\n",
      "terminal...\n",
      "Extracted text from page 341: An\tAside:\tGibbs\tSampling\n",
      "\n",
      "Generating\tsamples\tfrom\tsome\tdistributions\tis\teasy.\tWe\tcan\tget\tuniform\tran...\n",
      "Extracted text from page 342: y\twith\ta\trandom\tvalue\tpicked\tconditional\ton\tx.\tAfter\ta\tnumber\tof\titerations,\tthe\tresulting\n",
      "values\tof...\n",
      "Extracted text from page 343: Topic\tModeling\n",
      "\n",
      "When\twe\tbuilt\tour\tData\tScientists\tYou\tShould\tKnow\trecommender\tin\tChapter\t1,\twe\n",
      "simpl...\n",
      "Extracted text from page 344: the\twords\ton\twhich\tthey\tput\tthe\theaviest\tweight.\tWe\tjust\thave\tto\tsomehow\tgenerate\tthe\n",
      "document_topic...\n",
      "Extracted text from page 345: topic_word_counts\t=\t[Counter()\tfor\t_\tin\trange(K)]\n",
      "\n",
      "The\ttotal\tnumber\tof\twords\tassigned\tto\teach\ttopic:...\n",
      "Extracted text from page 346: def\tchoose_new_topic(d,\tword):\n",
      "\t\t\t\treturn\tsample_from([topic_weight(d,\tword,\tk)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t...\n",
      "Extracted text from page 347: Java\n",
      "\n",
      "R\n",
      "\n",
      "HBase\n",
      "\n",
      "regression\n",
      "\n",
      "Big\tData\n",
      "\n",
      "statistics\n",
      "\n",
      "Postgres\n",
      "\n",
      "libsvm\n",
      "\n",
      "Hadoop\n",
      "\n",
      "Python\n",
      "\n",
      "MongoDB scikit-l...\n",
      "Extracted text from page 348: For\tFurther\tExploration\n",
      "\n",
      "Natural\tLanguage\tToolkit\tis\ta\tpopular\t(and\tpretty\tcomprehensive)\tlibrary\tof...\n",
      "Extracted text from page 349: ...\n",
      "Extracted text from page 350: Chapter\t21.\tNetwork\tAnalysis\n",
      "\n",
      "Your\tconnections\tto\tall\tthe\tthings\taround\tyou\tliterally\tdefine\twho\tyou...\n",
      "Extracted text from page 351: Betweenness\tCentrality\n",
      "\n",
      "In\tChapter\t1,\twe\tcomputed\tthe\tkey\tconnectors\tin\tthe\tDataSciencester\tnetwork\t...\n",
      "Extracted text from page 352: That\tis,\tto\tfigure\tout\tThor’s\tbetweenness\tcentrality,\twe’ll\tneed\tto\tcompute\tall\tthe\tshortest\n",
      "paths\tb...\n",
      "Extracted text from page 353: We\tcan\tput\tthis\tall\ttogether\tinto\ta\t(large)\tfunction:\n",
      "\n",
      "from\tcollections\timport\tdeque\n",
      "\n",
      "def\tshortest_p...\n",
      "Extracted text from page 354: \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfor\tid\tin\tpath:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif\tid\tnot\tin\t[source_id,\ttarget_id]:\n",
      "\t\t\t\t\t\t\t\t\t\t\t...\n",
      "Extracted text from page 355: Figure\t21-3.\tThe\tDataSciencester\tnetwork\tsized\tby\tcloseness\tcentrality\n",
      "\n",
      "There\tis\tmuch\tless\tvariation...\n",
      "Extracted text from page 356: Eigenvector\tCentrality\n",
      "\n",
      "In\torder\tto\ttalk\tabout\teigenvector\tcentrality,\twe\thave\tto\ttalk\tabout\teigenve...\n",
      "Extracted text from page 357: Matrix\tMultiplication\n",
      "\n",
      "If\tA\tis\ta\t\n",
      "\n",
      "AB\tis\tthe\t\n",
      "\n",
      "\tmatrix\tand\tB\tis\ta\t\n",
      "\n",
      "\tmatrix,\tand\tif\t\n",
      "\n",
      ",\tthen\ttheir\tp...\n",
      "Extracted text from page 358: When\tA\tis\ta\tsquare\tmatrix,\tthis\toperation\tmaps\tn-dimensional\tvectors\tto\tother\tn-\n",
      "dimensional\tvectors...\n",
      "Extracted text from page 359: Centrality\n",
      "\n",
      "How\tdoes\tthis\thelp\tus\tunderstand\tthe\tDataSciencester\tnetwork?\n",
      "\n",
      "To\tstart\twith,\twe’ll\tneed...\n",
      "Extracted text from page 360: centrality.\tBeing\tan\teigenvector\tmeans\tthat\tif\tyou\tcompute:\n",
      "\n",
      "matrix_operate(adjacency_matrix,\teigenv...\n",
      "Extracted text from page 361: Directed\tGraphs\tand\tPageRank\n",
      "\n",
      "DataSciencester\tisn’t\tgetting\tmuch\ttraction,\tso\tthe\tVP\tof\tRevenue\tcons...\n",
      "Extracted text from page 362: Google\tto\trank\twebsites\tbased\ton\twhich\tother\twebsites\tlink\tto\tthem,\twhich\tother\twebsites\n",
      "link\tto\ttho...\n",
      "Extracted text from page 363: For\tFurther\tExploration\n",
      "\n",
      "There\tare\tmany\tother\tnotions\tof\tcentrality\tbesides\tthe\tones\twe\tused\t(althou...\n",
      "Extracted text from page 364: ...\n",
      "Extracted text from page 365: Chapter\t22.\tRecommender\tSystems\n",
      "\n",
      "O\tnature,\tnature,\twhy\tart\tthou\tso\tdishonest,\tas\tever\tto\tsend\tmen\twi...\n",
      "Extracted text from page 366: Manual\tCuration\n",
      "\n",
      "Before\tthe\tInternet,\twhen\tyou\tneeded\tbook\trecommendations\tyou\twould\tgo\tto\tthe\tlibra...\n",
      "Extracted text from page 367: Recommending\tWhat’s\tPopular\n",
      "\n",
      "One\teasy\tapproach\tis\tto\tsimply\trecommend\twhat’s\tpopular:\n",
      "\n",
      "popular_inter...\n",
      "Extracted text from page 368: User-Based\tCollaborative\tFiltering\n",
      "\n",
      "One\tway\tof\ttaking\ta\tuser’s\tinterests\tinto\taccount\tis\tto\tlook\tfor...\n",
      "Extracted text from page 369: after\twhich,\twe\tcan\tcreate\ta\tmatrix\tof\tuser\tinterests\tsimply\tby\tmap-ping\tthis\tfunction\n",
      "against\tthe\tl...\n",
      "Extracted text from page 370: \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\treverse=True)\n",
      "\n",
      "\t\t\t\t#\tand\t(maybe)\texclude\talready-interests\n",
      "\t\t\t\tif\tinclude_c...\n",
      "Extracted text from page 371: Item-Based\tCollaborative\tFiltering\n",
      "\n",
      "An\talternative\tapproach\tis\tto\tcompute\tsimilarities\tbetween\tinter...\n",
      "Extracted text from page 372: Now\twe\tcan\tcreate\trecommendations\tfor\ta\tuser\tby\tsumming\tup\tthe\tsimilarities\tof\tthe\n",
      "interests\tsimilar...\n",
      "Extracted text from page 373: For\tFurther\tExploration\n",
      "\n",
      "Crab\tis\ta\tframework\tfor\tbuilding\trecommender\tsystems\tin\tPython.\n",
      "\n",
      "Graphlab\ta...\n",
      "Extracted text from page 374: ...\n",
      "Extracted text from page 375: Chapter\t23.\tDatabases\tand\tSQL\n",
      "\n",
      "Memory\tis\tman’s\tgreatest\tfriend\tand\tworst\tenemy.\n",
      "\n",
      "Gilbert\tParker\n",
      "\n",
      "The...\n",
      "Extracted text from page 376: CREATE\tTABLE\tand\tINSERT\n",
      "\n",
      "A\trelational\tdatabase\tis\ta\tcollection\tof\ttables\t(and\tof\trelationships\tamong...\n",
      "Extracted text from page 377: \t\t\t\tdef\t__repr__(self):\n",
      "\t\t\t\t\t\t\t\t\"\"\"pretty\trepresentation\tof\tthe\ttable:\tcolumns\tthen\trows\"\"\"\n",
      "\t\t\t\t\t\t\t\t...\n",
      "Extracted text from page 378: UPDATE\n",
      "\n",
      "Sometimes\tyou\tneed\tto\tupdate\tthe\tdata\tthat’s\talready\tin\tthe\tdatabase.\tFor\tinstance,\tif\n",
      "Dunn\t...\n",
      "Extracted text from page 379: DELETE\n",
      "\n",
      "There\tare\ttwo\tways\tto\tdelete\trows\tfrom\ta\ttable\tin\tSQL.\tThe\tdangerous\tway\tdeletes\tevery\n",
      "row\tf...\n",
      "Extracted text from page 380: SELECT\n",
      "\n",
      "Typically\tyou\tdon’t\tinspect\tSQL\ttables\tdirectly.\tInstead\tyou\tquery\tthem\twith\ta\tSELECT\n",
      "statem...\n",
      "Extracted text from page 381: \t\t\t\t\t\t\t\treturn\tlimit_table\n",
      "\n",
      "after\twhich\twe\tcan\teasily\tconstruct\tNotQuiteABase\tequivalents\tto\tthe\tpre...\n",
      "Extracted text from page 382: GROUP\tBY\n",
      "\n",
      "Another\tcommon\tSQL\toperation\tis\tGROUP\tBY,\twhich\tgroups\ttogether\trows\twith\tidentical\n",
      "values...\n",
      "Extracted text from page 383: 2.\t Iterates\tover\tthe\trows\tof\tthe\ttable,\tpopulating\tthe\tdefaultdict.\n",
      "\n",
      "3.\t Creates\ta\tnew\ttable\twith\tt...\n",
      "Extracted text from page 384: user_id_sum\t=\tusers\t\\\n",
      "\t\t\t\t.where(lambda\trow:\trow[\"user_id\"]\t>\t1)\t\\\n",
      "\t\t\t\t.group_by(group_by_columns=[]...\n",
      "Extracted text from page 385: ORDER\tBY\n",
      "\n",
      "Frequently,\tyou’ll\twant\tto\tsort\tyour\tresults.\tFor\texample,\tyou\tmight\twant\tto\tknow\tthe\n",
      "(alp...\n",
      "Extracted text from page 386: JOIN\n",
      "\n",
      "Relational\tdatabase\ttables\tare\toften\tnormalized,\twhich\tmeans\tthat\tthey’re\torganized\tto\n",
      "minimiz...\n",
      "Extracted text from page 387: Using\ta\tLEFT\tJOIN,\tit’s\teasy\tto\tcount\tthe\tnumber\tof\tinterests\teach\tuser\thas:\n",
      "\n",
      "SELECT\tusers.id,\tCOUNT...\n",
      "Extracted text from page 388: matches,\tand\ta\tFULL\tOUTER\tJOIN,\twhich\tkeeps\trows\tfrom\tboth\ttables\tthat\thave\tno\n",
      "matches.\tWe\twon’t\timp...\n",
      "Extracted text from page 389: Subqueries\n",
      "\n",
      "In\tSQL,\tyou\tcan\tSELECT\tfrom\t(and\tJOIN)\tthe\tresults\tof\tqueries\tas\tif\tthey\twere\ttables.\tSo...\n",
      "Extracted text from page 390: Indexes\n",
      "\n",
      "To\tfind\trows\tcontaining\ta\tspecific\tvalue\t(say,\twhere\tname\tis\t“Hero”),\tNotQuiteABase\thas\n",
      "to\t...\n",
      "Extracted text from page 391: Query\tOptimization\n",
      "\n",
      "Recall\tthe\tquery\tto\tfind\tall\tusers\twho\tare\tinterested\tin\tSQL:\n",
      "\n",
      "SELECT\tusers.name...\n",
      "Extracted text from page 392: NoSQL\n",
      "\n",
      "A\trecent\ttrend\tin\tdatabases\tis\ttoward\tnonrelational\t“NoSQL”\tdatabases,\twhich\tdon’t\n",
      "represent\t...\n",
      "Extracted text from page 393: For\tFurther\tExploration\n",
      "\n",
      "If\tyou’d\tlike\tto\tdownload\ta\trelational\tdatabase\tto\tplay\twith,\tSQLite\tis\tfas...\n",
      "Extracted text from page 394: ...\n",
      "Extracted text from page 395: Chapter\t24.\tMapReduce\n",
      "\n",
      "The\tfuture\thas\talready\tarrived.\tIt’s\tjust\tnot\tevenly\tdistributed\tyet.\n",
      "\n",
      "Willia...\n",
      "Extracted text from page 396: Example:\tWord\tCount\n",
      "\n",
      "DataSciencester\thas\tgrown\tto\tmillions\tof\tusers!\tThis\tis\tgreat\tfor\tyour\tjob\tsecu...\n",
      "Extracted text from page 397: Imagine\tthat\twe\thave\tthree\tdocuments\t[\"data\tscience\",\t\"big\tdata\",\t\"science\n",
      "fiction\"].\n",
      "\n",
      "Then\twc_mappe...\n",
      "Extracted text from page 398: Why\tMapReduce?\n",
      "\n",
      "As\tmentioned\tearlier,\tthe\tprimary\tbenefit\tof\tMapReduce\tis\tthat\tit\tallows\tus\tto\tdistr...\n",
      "Extracted text from page 399: MapReduce\tMore\tGenerally\n",
      "\n",
      "If\tyou\tthink\tabout\tit\tfor\ta\tminute,\tall\tof\tthe\tword-count-specific\tcode\tin...\n",
      "Extracted text from page 400: Example:\tAnalyzing\tStatus\tUpdates\n",
      "\n",
      "The\tcontent\tVP\twas\timpressed\twith\tthe\tword\tcounts\tand\tasks\twhat\te...\n",
      "Extracted text from page 401: \t\t\t\tword,\tcount\t=\tword_counts.most_common(1)[0]\n",
      "\n",
      "\t\t\t\tyield\t(user,\t(word,\tcount))\n",
      "\n",
      "user_words\t=\tmap_r...\n",
      "Extracted text from page 402: Example:\tMatrix\tMultiplication\n",
      "\n",
      "Recall\tfrom\t“Matrix\tMultiplication”\tthat\tgiven\ta\t\n",
      "B,\twe\tcan\tmultiply...\n",
      "Extracted text from page 403: \t\t\t\tif\tsum_product\t!=\t0.0:\n",
      "\t\t\t\t\t\t\t\tyield\t(key,\tsum_product)\n",
      "\n",
      "For\texample,\tif\tyou\thad\tthe\ttwo\tmatrice...\n",
      "Extracted text from page 404: An\tAside:\tCombiners\n",
      "\n",
      "One\tthing\tyou\thave\tprobably\tnoticed\tis\tthat\tmany\tof\tour\tmappers\tseem\tto\tinclude...\n",
      "Extracted text from page 405: For\tFurther\tExploration\n",
      "\n",
      "The\tmost\twidely\tused\tMapReduce\tsystem\tis\tHadoop,\twhich\titself\tmerits\tmany\tb...\n",
      "Extracted text from page 406: ...\n",
      "Extracted text from page 407: Chapter\t25.\tGo\tForth\tand\tDo\tData\n",
      "Science\n",
      "\n",
      "And\tnow,\tonce\tagain,\tI\tbid\tmy\thideous\tprogeny\tgo\tforth\tand...\n",
      "Extracted text from page 408: IPython\n",
      "\n",
      "We\tmentioned\tIPython\tearlier\tin\tthe\tbook.\tIt\tprovides\ta\tshell\twith\tfar\tmore\tfunctionality\n",
      "t...\n",
      "Extracted text from page 409: Mathematics\n",
      "\n",
      "Throughout\tthis\tbook,\twe\tdabbled\tin\tlinear\talgebra\t(Chapter\t4),\tstatistics\t(Chapter\t5),...\n",
      "Extracted text from page 410: Not\tfrom\tScratch\n",
      "\n",
      "Implementing\tthings\t“from\tscratch”\tis\tgreat\tfor\tunderstanding\thow\tthey\twork.\tBut\ti...\n",
      "Extracted text from page 411: NumPy\n",
      "\n",
      "NumPy\t(for\t“Numeric\tPython”)\tprovides\tfacilities\tfor\tdoing\t“real”\tscientific\tcomputing.\n",
      "It\tfe...\n",
      "Extracted text from page 412: pandas\n",
      "\n",
      "pandas\tprovides\tadditional\tdata\tstructures\tfor\tworking\twith\tdata\tsets\tin\tPython.\tIts\n",
      "primary...\n",
      "Extracted text from page 413: scikit-learn\n",
      "\n",
      "scikit-learn\tis\tprobably\tthe\tmost\tpopular\tlibrary\tfor\tdoing\tmachine\tlearning\tin\tPython...\n",
      "Extracted text from page 414: Visualization\n",
      "\n",
      "The\tmatplotlib\tcharts\twe’ve\tbeen\tcreating\thave\tbeen\tclean\tand\tfunctional\tbut\tnot\n",
      "part...\n",
      "Extracted text from page 415: R\n",
      "\n",
      "Although\tyou\tcan\ttotally\tget\taway\twith\tnot\tlearning\tR,\ta\tlot\tof\tdata\tscientists\tand\tdata\n",
      "science\t...\n",
      "Extracted text from page 416: Find\tData\n",
      "\n",
      "If\tyou’re\tdoing\tdata\tscience\tas\tpart\tof\tyour\tjob,\tyou’ll\tmost\tlikely\tget\tthe\tdata\tas\tpart...\n",
      "Extracted text from page 417: Do\tData\tScience\n",
      "\n",
      "Looking\tthrough\tdata\tcatalogs\tis\tfine,\tbut\tthe\tbest\tprojects\t(and\tproducts)\tare\tone...\n",
      "Extracted text from page 418: Hacker\tNews\n",
      "\n",
      "Hacker\tNews\tis\ta\tnews\taggregation\tand\tdiscussion\tsite\tfor\ttechnology-related\tnews.\tIt\n",
      "c...\n",
      "Extracted text from page 419: Fire\tTrucks\n",
      "\n",
      "I\tlive\ton\ta\tmajor\tstreet\tin\tdowntown\tSeattle,\thalfway\tbetween\ta\tfire\tstation\tand\tmost\to...\n",
      "Extracted text from page 420: T-shirts\n",
      "\n",
      "I\thave\ta\tyoung\tdaughter,\tand\tan\tincessant\tsource\tof\tfrustration\tto\tme\tthroughout\ther\n",
      "child...\n",
      "Extracted text from page 421: And\tYou?\n",
      "\n",
      "What\tinterests\tyou?\tWhat\tquestions\tkeep\tyou\tup\tat\tnight?\tLook\tfor\ta\tdata\tset\t(or\tscrape\n",
      "so...\n",
      "Extracted text from page 422: ...\n",
      "Extracted text from page 423: Index\n",
      "\n",
      "A\n",
      "\n",
      "A/B\ttest,\tExample:\tRunning\tan\tA/B\tTest\n",
      "\n",
      "accuracy,\tCorrectness\n",
      "\n",
      "of\tmodel\tperformance,\tCorre...\n",
      "Extracted text from page 424: B\n",
      "\n",
      "backpropagation,\tBackpropagation\n",
      "\n",
      "bagging,\tRandom\tForests\n",
      "\n",
      "bar\tcharts,\tBar\tCharts-Line\tCharts\n",
      "\n",
      "Ba...\n",
      "Extracted text from page 425: business\tmodels,\tModeling\n",
      "\n",
      "C\n",
      "\n",
      "CAPTCHA,\tdefeating\twith\ta\tneural\tnetwork,\tExample:\tDefeating\ta\tCAPTCHA...\n",
      "Extracted text from page 426: example,\tclustering\tcolors,\tExample:\tClustering\tColors\n",
      "\n",
      "example,\tmeetups,\tExample:\tMeetups-Example:\t...\n",
      "Extracted text from page 427: in\tsimple\tlinear\tregression,\tThe\tModel\n",
      "\n",
      "other\tcaveats,\tSome\tOther\tCorrelational\tCaveats\n",
      "\n",
      "outliers\tan...\n",
      "Extracted text from page 428: using\tAPIs,\tUsing\tAPIs-Using\tTwython\n",
      "\n",
      "using\tstdin\tand\tstdout,\tstdin\tand\tstdout\n",
      "\n",
      "manipulating,\tManipu...\n",
      "Extracted text from page 429: GROUP\tBY\tstatement,\tGROUP\tBY-GROUP\tBY\n",
      "\n",
      "JOIN\tstatement,\tJOIN\n",
      "\n",
      "NoSQL,\tNoSQL\n",
      "\n",
      "ORDER\tBY\tstatement,\tORDER...\n",
      "Extracted text from page 430: dimensionality\treduction,\tDimensionality\tReduction-Dimensionality\tReduction\n",
      "\n",
      "using\tprincipal\tcompone...\n",
      "Extracted text from page 431: eigenvector\tcentrality,\tEigenvector\tCentrality-Centrality\n",
      "\n",
      "ensemble\tlearning,\tRandom\tForests\n",
      "\n",
      "entrop...\n",
      "Extracted text from page 432: files,\treading,\tReading\tFiles\n",
      "\n",
      "delimited\tfiles,\tDelimited\tFiles\n",
      "\n",
      "text\tfiles,\tThe\tBasics\tof\tText\tFile...\n",
      "Extracted text from page 433: grammars,\tGrammars-Grammars\n",
      "\n",
      "greedy\talgorithms,\tCreating\ta\tDecision\tTree\n",
      "\n",
      "GROUP\tBY\tstatement\t(SQL),\t...\n",
      "Extracted text from page 434: if\tstatements\t(Python),\tControl\tFlow\n",
      "\n",
      "if-then-else\tstatements\t(Python),\tControl\tFlow\n",
      "\n",
      "in\toperator\t(P...\n",
      "Extracted text from page 435: k-nearest\tneighbors\tclassification\t(see\tnearest\tneighbors\tclassification)\n",
      "\n",
      "kernel\ttrick,\tSupport\tVec...\n",
      "Extracted text from page 436: goodness\tof\tfit,\tGoodness\tof\tFit\n",
      "\n",
      "interpreting\tthe\tmodel,\tInterpreting\tthe\tModel\n",
      "\n",
      "model,\tThe\tModel\n",
      "\n",
      "...\n",
      "Extracted text from page 437: machine\tlearning,\tMachine\tLearning-For\tFurther\tExploration\n",
      "\n",
      "bias-variance\ttrade-off,\tThe\tBias-Varian...\n",
      "Extracted text from page 438: matrix\tmultiplication,\tMatrix\tMultiplication\n",
      "\n",
      "using\tMapReduce,\tExample:\tMatrix\tMultiplication-Exampl...\n",
      "Extracted text from page 439: trigrams,\tn-gram\tModels\n",
      "\n",
      "n-grams,\tn-gram\tModels\n",
      "\n",
      "Naive\tBayes\talgorithm,\tNaive\tBayes-For\tFurther\tExpl...\n",
      "Extracted text from page 440: neural\tnetworks,\tNeural\tNetworks-For\tFurther\tExploration\n",
      "\n",
      "backpropagation,\tBackpropagation\n",
      "\n",
      "example,...\n",
      "Extracted text from page 441: one-sided\ttests,\tExample:\tFlipping\ta\tCoin\n",
      "\n",
      "ORDER\tBY\tstatement\t(SQL),\tORDER\tBY\n",
      "\n",
      "overfitting,\tOverfitt...\n",
      "Extracted text from page 442: probability,\tProbability-For\tFurther\tExploration,\tMathematics\n",
      "\n",
      "Bayes’s\tTheorem,\tBayes’s\tTheorem\n",
      "\n",
      "cen...\n",
      "Extracted text from page 443: generators\tand\titerators,\tGenerators\tand\tIterators\n",
      "\n",
      "list\tcomprehensions,\tList\tComprehensions\n",
      "\n",
      "lists,...\n",
      "Extracted text from page 444: conditioned\ton\tevents,\tRandom\tVariables\n",
      "\n",
      "expected\tvalue,\tRandom\tVariables\n",
      "\n",
      "normal,\tThe\tNormal\tDistri...\n",
      "Extracted text from page 445: rescaling\tdata,\tRescaling-Rescaling,\tRegularization\n",
      "\n",
      "ridge\tregression,\tRegularization\n",
      "\n",
      "right\tjoins,\t...\n",
      "Extracted text from page 446: SQL\t(Structured\tQuery\tLanguage),\tDatabases\tand\tSQL\n",
      "\n",
      "(see\talso\tdatabases\tand\tSQL)\n",
      "\n",
      "square\tbrackets\t([...\n",
      "Extracted text from page 447: sum\tof\tsquares,\tcomputing\tfor\ta\tvector,\tVectors\n",
      "\n",
      "supervised\tlearning,\tClustering\n",
      "\n",
      "supervised\tmodels,...\n",
      "Extracted text from page 448: U\n",
      "\n",
      "underfitting,\tOverfitting\tand\tUnderfitting,\tThe\tBias-Variance\tTrade-off\n",
      "\n",
      "uniform\tdistribution,\tCo...\n",
      "Extracted text from page 449: whitespace\tin\tPython\tcode,\tWhitespace\tFormatting\n",
      "\n",
      "word\tclouds,\tWord\tClouds-Word\tClouds\n",
      "\n",
      "X\n",
      "\n",
      "XML\tdata\t...\n",
      "Extracted text from page 450: ...\n",
      "Extracted text from page 451: About\tthe\tAuthor\n",
      "\n",
      "Joel\tGrus\tis\ta\tsoftware\tengineer\tat\tGoogle.\tPreviously\the\tworked\tas\ta\tdata\tscienti...\n",
      "Extracted text from page 452: ...\n",
      "Extracted text from page 453: Colophon\n",
      "\n",
      "The\tanimal\ton\tthe\tcover\tof\tData\tScience\tfrom\tScratch\tis\ta\tRock\tPtarmigan\t(Lagopus\n",
      "muta).\tT...\n",
      "Extracted text from page 454: Preface\n",
      "\n",
      "Data\tScience\n",
      "\n",
      "From\tScratch\n",
      "\n",
      "Conventions\tUsed\tin\tThis\tBook\n",
      "\n",
      "Using\tCode\tExamples\n",
      "\n",
      "Safari®\tBoo...\n",
      "Extracted text from page 455: Strings\n",
      "\n",
      "Exceptions\n",
      "\n",
      "Lists\n",
      "\n",
      "Tuples\n",
      "\n",
      "Dictionaries\n",
      "\n",
      "Sets\n",
      "\n",
      "Control\tFlow\n",
      "\n",
      "Truthiness\n",
      "\n",
      "The\tNot-So-Basics\n",
      "...\n",
      "Extracted text from page 456: Scatterplots\n",
      "\n",
      "For\tFurther\tExploration\n",
      "\n",
      "4.\tLinear\tAlgebra\n",
      "\n",
      "Vectors\n",
      "\n",
      "Matrices\n",
      "\n",
      "For\tFurther\tExploration...\n",
      "Extracted text from page 457: Example:\tFlipping\ta\tCoin\n",
      "\n",
      "Confidence\tIntervals\n",
      "\n",
      "P-hacking\n",
      "\n",
      "Example:\tRunning\tan\tA/B\tTest\n",
      "\n",
      "Bayesian\tIn...\n",
      "Extracted text from page 458: Example:\tUsing\tthe\tTwitter\tAPIs\n",
      "\n",
      "Getting\tCredentials\n",
      "\n",
      "For\tFurther\tExploration\n",
      "\n",
      "10.\tWorking\twith\tData...\n",
      "Extracted text from page 459: 13.\tNaive\tBayes\n",
      "\n",
      "A\tReally\tDumb\tSpam\tFilter\n",
      "\n",
      "A\tMore\tSophisticated\tSpam\tFilter\n",
      "\n",
      "Implementation\n",
      "\n",
      "Testin...\n",
      "Extracted text from page 460: Support\tVector\tMachines\n",
      "\n",
      "For\tFurther\tInvestigation\n",
      "\n",
      "17.\tDecision\tTrees\n",
      "\n",
      "What\tIs\ta\tDecision\tTree?\n",
      "\n",
      "En...\n",
      "Extracted text from page 461: n-gram\tModels\n",
      "\n",
      "Grammars\n",
      "\n",
      "An\tAside:\tGibbs\tSampling\n",
      "\n",
      "Topic\tModeling\n",
      "\n",
      "For\tFurther\tExploration\n",
      "\n",
      "21.\tNetw...\n",
      "Extracted text from page 462: Subqueries\n",
      "\n",
      "Indexes\n",
      "\n",
      "Query\tOptimization\n",
      "\n",
      "NoSQL\n",
      "\n",
      "For\tFurther\tExploration\n",
      "\n",
      "24.\tMapReduce\n",
      "\n",
      "Example:\tWor...\n",
      "Extracted text from page 463: T-shirts\n",
      "\n",
      "And\tYou?\n",
      "\n",
      "Index\n",
      "\n",
      "...\n",
      "Extracted text from page 464: ...\n",
      "Text content extracted and saved to data/text_content.json\n",
      "File data/text_content.json created successfully and is not empty\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        text_content = {}\n",
    "        text = extract_text(pdf_path)\n",
    "        pages = text.split('\\x0c')\n",
    "        \n",
    "        for page_num, page_text in enumerate(pages):\n",
    "            text_content[str(page_num)] = page_text.strip()\n",
    "            print(f\"Extracted text from page {page_num}: {page_text[:100]}...\")  # Print first 100 characters of the page text\n",
    "\n",
    "        return text_content\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the path to your PDF file directly\n",
    "    pdf_path = r\"C:\\Users\\Yadav Ji\\Desktop\\Data_Science.pdf\"\n",
    "    \n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"File not found: {pdf_path}\")\n",
    "    else:\n",
    "        text_content = extract_text_from_pdf(pdf_path)\n",
    "        \n",
    "        if text_content is not None:\n",
    "            # Ensure the 'data' directory exists\n",
    "            if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                print(f\"Created directory 'data'\")\n",
    "            \n",
    "            json_file_path = \"data/text_content.json\"\n",
    "            with open(json_file_path, \"w\") as file:\n",
    "                json.dump(text_content, file, indent=4)\n",
    "                print(f\"Text content extracted and saved to {json_file_path}\")\n",
    "\n",
    "            # Verify if the file was created and has content\n",
    "            if os.path.exists(json_file_path):\n",
    "                with open(json_file_path, \"r\") as file:\n",
    "                    content = file.read()\n",
    "                    if content.strip():\n",
    "                        print(f\"File {json_file_path} created successfully and is not empty\")\n",
    "                    else:\n",
    "                        print(f\"File {json_file_path} is empty\")\n",
    "        else:\n",
    "            print(\"No text content extracted from the PDF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f084596-a4da-443a-a8e3-919eacf04c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f47cf7-4253-4a70-b89a-f76473f3a1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical tree created and saved to data/hierarchical_tree.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, identifier, content):\n",
    "        self.id = identifier\n",
    "        self.content = content\n",
    "        self.children = []\n",
    "\n",
    "def create_hierarchical_tree(text_content):\n",
    "    root = Node(\"root\", \"Entire Textbook\")\n",
    "    \n",
    "    # This is a simplified example. You would parse the text_content to identify chapters and sections.\n",
    "    # Let's assume each page is a chapter for this example\n",
    "    for page_num, page_text in text_content.items():\n",
    "        chapter = Node(f\"chapter_{page_num}\", f\"Chapter {int(page_num) + 1}\")\n",
    "        section = Node(f\"section_{page_num}_1\", f\"Section {int(page_num) + 1}.1\")\n",
    "        section.children.append(Node(f\"paragraph_{page_num}_1_1\", page_text))\n",
    "        \n",
    "        chapter.children.append(section)\n",
    "        root.children.append(chapter)\n",
    "    \n",
    "    return root\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    json_file_path = \"data/text_content.json\"\n",
    "    \n",
    "    if not os.path.exists(json_file_path):\n",
    "        print(f\"File not found: {json_file_path}\")\n",
    "    else:\n",
    "        with open(json_file_path, \"r\") as file:\n",
    "            text_content = json.load(file)\n",
    "        \n",
    "        tree = create_hierarchical_tree(text_content)\n",
    "        \n",
    "        # Save the tree to a file\n",
    "        tree_file_path = \"data/hierarchical_tree.json\"\n",
    "        with open(tree_file_path, \"w\") as file:\n",
    "            json.dump(tree.__dict__, file, default=lambda o: o.__dict__, indent=4)\n",
    "        print(f\"Hierarchical tree created and saved to {tree_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5bdceda-0e91-46bc-9e1b-3f6649cf4039",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rank_bm25'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrank_bm25\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BM25Okapi\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DPRQuestionEncoderTokenizer, DPRQuestionEncoder, DPRContextEncoder, DPRContextEncoderTokenizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rank_bm25'"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from transformers import DPRQuestionEncoderTokenizer, DPRQuestionEncoder, DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import json\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b471139-d68b-4ad5-b859-6d7c338fd578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Results: [464 158 146 147 148 149 150 151 152 153 154 155 156 157 159 231 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 145 144 143 142 117 118 119 120\n",
      " 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n",
      " 139 140 141 172 173 174 203 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 204 202 175 201\n",
      " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
      " 194 195 196 197 198 199 200 116 115 114  28  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  29  27  56  26   1   2   3   4   5   6   7   8   9  10  11  12  13  14\n",
      "  15  16  17  18  19  20  21  22  23  24  25  55  57 113  86  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112  87  85  58  84  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83 230 232 463\n",
      " 391 379 380 381 382 383 384 385 386 387 388 389 390 392 233 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 378 377 376 375 350 351 352 353 354\n",
      " 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372\n",
      " 373 374 405 406 407 436 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 437 435 408 434 409\n",
      " 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427\n",
      " 428 429 430 431 432 433 349 348 347 261 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 262\n",
      " 260 289 259 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248\n",
      " 249 250 251 252 253 254 255 256 257 258 288 290 346 319 321 322 323 324\n",
      " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
      " 343 344 345 320 318 291 317 292 293 294 295 296 297 298 299 300 301 302\n",
      " 303 304 305 306 307 308 309 310 311 312 313 314 315 316   0] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25 Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bm25_indices, bm25_scores)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# DPR Retrieval\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m dpr_indices, dpr_scores \u001b[38;5;241m=\u001b[39m dpr_retrieval(relevant_sections, query)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDPR Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dpr_indices, dpr_scores)\n",
      "Cell \u001b[1;32mIn[17], line 28\u001b[0m, in \u001b[0;36mdpr_retrieval\u001b[1;34m(corpus, query)\u001b[0m\n\u001b[0;32m     25\u001b[0m context_tokenizer \u001b[38;5;241m=\u001b[39m DPRContextEncoderTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/dpr-ctx_encoder-single-nq-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m question_embedding \u001b[38;5;241m=\u001b[39m question_encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mquestion_tokenizer(query, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 28\u001b[0m context_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[0;32m     29\u001b[0m     context_encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcontext_tokenizer(doc, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m corpus\n\u001b[0;32m     31\u001b[0m ])\n\u001b[0;32m     33\u001b[0m similarities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(context_embeddings, question_embedding\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(similarities)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], np\u001b[38;5;241m.\u001b[39msort(similarities)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[17], line 29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     25\u001b[0m context_tokenizer \u001b[38;5;241m=\u001b[39m DPRContextEncoderTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/dpr-ctx_encoder-single-nq-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m question_embedding \u001b[38;5;241m=\u001b[39m question_encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mquestion_tokenizer(query, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     28\u001b[0m context_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m---> 29\u001b[0m     context_encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcontext_tokenizer(doc, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m corpus\n\u001b[0;32m     31\u001b[0m ])\n\u001b[0;32m     33\u001b[0m similarities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(context_embeddings, question_embedding\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(similarities)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], np\u001b[38;5;241m.\u001b[39msort(similarities)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\transformers\\models\\dpr\\modeling_dpr.py:485\u001b[0m, in \u001b[0;36mDPRContextEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m--> 485\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx_encoder(\n\u001b[0;32m    486\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    487\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    488\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m    489\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    490\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    491\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    492\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    493\u001b[0m )\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\transformers\\models\\dpr\\modeling_dpr.py:180\u001b[0m, in \u001b[0;36mDPREncoder.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    172\u001b[0m     input_ids: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m     return_dict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    179\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[BaseModelOutputWithPooling, Tuple[Tensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]:\n\u001b[1;32m--> 180\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_model(\n\u001b[0;32m    181\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    182\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    183\u001b[0m         token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m    184\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    185\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    186\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    187\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    190\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m sequence_output[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1142\u001b[0m     embedding_output,\n\u001b[0;32m   1143\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1144\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1145\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1146\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1147\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1148\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1149\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1150\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1151\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1152\u001b[0m )\n\u001b[0;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    685\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m         output_attentions,\n\u001b[0;32m    692\u001b[0m     )\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    695\u001b[0m         hidden_states,\n\u001b[0;32m    696\u001b[0m         attention_mask,\n\u001b[0;32m    697\u001b[0m         layer_head_mask,\n\u001b[0;32m    698\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    699\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    700\u001b[0m         past_key_value,\n\u001b[0;32m    701\u001b[0m         output_attentions,\n\u001b[0;32m    702\u001b[0m     )\n\u001b[0;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:584\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    574\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 584\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m    585\u001b[0m         hidden_states,\n\u001b[0;32m    586\u001b[0m         attention_mask,\n\u001b[0;32m    587\u001b[0m         head_mask,\n\u001b[0;32m    588\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    589\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[0;32m    590\u001b[0m     )\n\u001b[0;32m    591\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:523\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    506\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    512\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    514\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    515\u001b[0m         hidden_states,\n\u001b[0;32m    516\u001b[0m         attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m         output_attentions,\n\u001b[0;32m    522\u001b[0m     )\n\u001b[1;32m--> 523\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    524\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:467\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    465\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    466\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m--> 467\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlayer_norm(\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\torch\\nn\\functional.py:2573\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2571\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2572\u001b[0m     )\n\u001b[1;32m-> 2573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlayer_norm(\u001b[38;5;28minput\u001b[39m, normalized_shape, weight, bias, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_tree(tree_file_path):\n",
    "    with open(tree_file_path, \"r\") as file:\n",
    "        tree = json.load(file)\n",
    "    return tree\n",
    "\n",
    "def traverse_tree(node, query, depth=0):\n",
    "    if not node[\"children\"]:\n",
    "        return [(node[\"content\"], depth)]\n",
    "    results = []\n",
    "    for child in node[\"children\"]:\n",
    "        results.extend(traverse_tree(child, query, depth + 1))\n",
    "    return results\n",
    "\n",
    "def retrieve_relevant_sections(tree, query):\n",
    "    root = tree\n",
    "    all_sections = traverse_tree(root, query)\n",
    "    all_sections.sort(key=lambda x: x[1])  # Sort by depth\n",
    "    return [section[0] for section in all_sections]\n",
    "\n",
    "def dpr_retrieval(corpus, query):\n",
    "    question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "    question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "\n",
    "    context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "    context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "\n",
    "    question_embedding = question_encoder(**question_tokenizer(query, return_tensors='pt', truncation=True, padding=True, max_length=512))[0].detach().numpy()\n",
    "    context_embeddings = np.array([\n",
    "        context_encoder(**context_tokenizer(doc, return_tensors='pt', truncation=True, padding=True, max_length=512))[0].detach().numpy()\n",
    "        for doc in corpus\n",
    "    ])\n",
    "\n",
    "    similarities = np.dot(context_embeddings, question_embedding.T).squeeze()\n",
    "    return np.argsort(similarities)[::-1], np.sort(similarities)[::-1]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tree_file_path = \"data/hierarchical_tree.json\"\n",
    "    tree = load_tree(tree_file_path)\n",
    "    \n",
    "    query = \"Your query here\"\n",
    "    relevant_sections = retrieve_relevant_sections(tree, query)\n",
    "    \n",
    "    # BM25 Retrieval (assuming you have implemented it elsewhere)\n",
    "    bm25_indices, bm25_scores = bm25_retrieval(corpus, query)\n",
    "    print(\"BM25 Results:\", bm25_indices, bm25_scores)\n",
    "\n",
    "    # DPR Retrieval\n",
    "    dpr_indices, dpr_scores = dpr_retrieval(relevant_sections, query)\n",
    "    print(\"DPR Results:\", dpr_indices, dpr_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a637b5-57b6-4376-b0af-4ce51c3d9d60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_tree(tree_file_path):\n",
    "    with open(tree_file_path, \"r\") as file:\n",
    "        tree = json.load(file)\n",
    "    return tree\n",
    "\n",
    "def traverse_tree(node, query, depth=0):\n",
    "    if not node[\"children\"]:\n",
    "        return [(node[\"content\"], depth)]\n",
    "    results = []\n",
    "    for child in node[\"children\"]:\n",
    "        results.extend(traverse_tree(child, query, depth + 1))\n",
    "    return results\n",
    "\n",
    "def retrieve_relevant_sections(tree, query):\n",
    "    root = tree\n",
    "    all_sections = traverse_tree(root, query)\n",
    "    all_sections.sort(key=lambda x: x[1])  # Sort by depth\n",
    "    return [section[0] for section in all_sections]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tree_file_path = \"data/hierarchical_tree.json\"\n",
    "    tree = load_tree(tree_file_path)\n",
    "    \n",
    "    query = \"Your query here\"\n",
    "    relevant_sections = retrieve_relevant_sections(tree, query)\n",
    "    \n",
    "    # Use a language model to generate answers\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "    answers = [qa_pipeline(question=query, context=section) for section in relevant_sections]\n",
    "    \n",
    "    for answer in answers:\n",
    "        print(f\"Answer: {answer['answer']}, Score: {answer['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d96d779-0e10-4092-b28e-e1609e063671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 10:13:27.191 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\anaconda\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "def load_tree(tree_file_path):\n",
    "    with open(tree_file_path, \"r\") as file:\n",
    "        tree = json.load(file)\n",
    "    return tree\n",
    "\n",
    "def traverse_tree(node, query, depth=0):\n",
    "    if not node[\"children\"]:\n",
    "        return [(node[\"content\"], depth)]\n",
    "    results = []\n",
    "    for child in node[\"children\"]:\n",
    "        results.extend(traverse_tree(child, query, depth + 1))\n",
    "    return results\n",
    "\n",
    "def retrieve_relevant_sections(tree, query):\n",
    "    root = tree\n",
    "    all_sections = traverse_tree(root, query)\n",
    "    all_sections.sort(key=lambda x: x[1])  # Sort by depth\n",
    "    return [section[0] for section in all_sections]\n",
    "\n",
    "st.title(\"Textbook QA System\")\n",
    "\n",
    "query = st.text_input(\"Enter your query:\")\n",
    "if query:\n",
    "    tree_file_path = \"data/hierarchical_tree.json\"\n",
    "    tree = load_tree(tree_file_path)\n",
    "    \n",
    "    relevant_sections = retrieve_relevant_sections(tree, query)\n",
    "    \n",
    "    # Use a language model to generate answers\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "    answers = [qa_pipeline(question=query, context=section) for section in relevant_sections]\n",
    "    \n",
    "    for answer in answers:\n",
    "        st.write(f\"Answer: {answer['answer']}, Score: {answer['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccea81-8316-4a1f-99c1-5eaf4e5d5b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
